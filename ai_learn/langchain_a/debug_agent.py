"""
æ¼”ç¤º LangChain Function Calling çš„å®é™…è¿‡ç¨‹
"""
import os
from dotenv import load_dotenv
from langchain_community.chat_models.tongyi import ChatTongyi
from langchain.agents import create_agent
from weather_tools import tools

load_dotenv()

# åˆ›å»º LLM
llm = ChatTongyi(model="qwen-plus", temperature=0)

# åˆ›å»º Agent
agent = create_agent(
    model=llm,
    tools=tools,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢åŠ©æ‰‹"
)

print("=" * 60)
print("ğŸ” Function Calling è°ƒè¯•æ¼”ç¤º")
print("=" * 60)

# è°ƒç”¨ Agent
print("\nğŸ“ ç”¨æˆ·è¾“å…¥: 'åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·'\n")
print("-" * 60)

result = agent.invoke(
    {"messages": [("user", "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·")]},
    config={"configurable": {"thread_id": "debug"}}
)

print("-" * 60)
print("\nğŸ“Š Agent æ‰§è¡Œè¿‡ç¨‹ï¼ˆmessages åˆ—è¡¨ï¼‰:\n")

for i, msg in enumerate(result["messages"]):
    print(f"\n[æ¶ˆæ¯ {i+1}] ç±»å‹: {type(msg).__name__}")
    print(f"å†…å®¹: {msg.content[:100] if hasattr(msg, 'content') else msg}...")

    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if hasattr(msg, 'tool_calls') and msg.tool_calls:
        print(f"ğŸ”§ å·¥å…·è°ƒç”¨: {len(msg.tool_calls)} ä¸ª")
        for j, tool_call in enumerate(msg.tool_calls):
            print(f"   [{j+1}] å‡½æ•°å: {tool_call['name']}")
            print(f"       å‚æ•°: {tool_call['args']}")

print("\n" + "=" * 60)
print("âœ… å®Œæ•´æµç¨‹:")
print("   1. ç”¨æˆ·è¾“å…¥ â†’ LLM åˆ†æ")
print("   2. LLM å†³å®šè°ƒç”¨ get_weather(city='åŒ—äº¬')")
print("   3. æ‰§è¡Œå·¥å…·å‡½æ•°ï¼Œè·å–å¤©æ°”æ•°æ®")
print("   4. å°†ç»“æœè¿”å›ç»™ LLM")
print("   5. LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤")
print("=" * 60)
