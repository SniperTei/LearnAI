# çº¿æ€§å›å½’å…¥é—¨ - æˆ¿ä»·é¢„æµ‹é¡¹ç›®

> è¾¹å­¦æœºå™¨å­¦ä¹ ç®—æ³•è¾¹å­¦æ•°å­¦çš„å®æˆ˜æ•™ç¨‹

## ğŸ“š é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„çº¿æ€§å›å½’å…¥é—¨é¡¹ç›®ï¼Œé€šè¿‡é¢„æµ‹æˆ¿ä»·çš„å®é™…æ¡ˆä¾‹ï¼Œå¸®åŠ©ç†è§£æœºå™¨å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µã€‚ä¸éœ€è¦æ·±åšçš„æ•°å­¦åŸºç¡€ï¼Œè¾¹åšè¾¹å­¦ï¼

### å­¦ä¹ ç›®æ ‡

- âœ… ç†è§£çº¿æ€§å›å½’çš„åŸºæœ¬åŸç†
- âœ… æŒæ¡4ä¸ªæ ¸å¿ƒæ•°å­¦æ¦‚å¿µ
- âœ… å­¦ä¼šä½¿ç”¨scikit-learnåº“
- âœ… å®Œæˆç¬¬ä¸€ä¸ªæœºå™¨å­¦ä¹ é¡¹ç›®

---

## ğŸ¯ ä½ å°†å­¦åˆ°çš„æ•°å­¦æ¦‚å¿µ

| æ¦‚å¿µ | ç¬¦å· | åº”ç”¨ | éš¾åº¦ |
|------|------|------|------|
| **å‡å€¼** | Î¼ | ç†è§£æ•°æ®ä¸­å¿ƒ | â­ |
| **æ±‚å’Œç¬¦å·** | Î£ | ç´¯åŠ è®¡ç®— | â­ |
| **å‡æ–¹è¯¯å·®** | MSE | è¡¡é‡é¢„æµ‹å¥½å | â­â­ |
| **æ¢¯åº¦ä¸‹é™** | âˆ‡ | è‡ªåŠ¨æ‰¾æœ€ä¼˜å‚æ•° | â­â­â­ |

---

## ğŸ“ æ–‡ä»¶è¯´æ˜

```
linear_regression/
â”œâ”€â”€ linear_regression_demo.py    # ä¸»ç¨‹åºï¼ˆåŒ…å«æ‰€æœ‰æ•™å­¦ä»£ç ï¼‰
â”œâ”€â”€ house_prices_scatter.png     # æ•°æ®æ•£ç‚¹å›¾
â”œâ”€â”€ house_prices_try1.png        # ç¬¬ä¸€æ¬¡å°è¯•ï¼ˆw=3, b=0ï¼‰
â”œâ”€â”€ house_prices_try2.png        # ç¬¬äºŒæ¬¡å°è¯•ï¼ˆw=2.5, b=50ï¼‰
â”œâ”€â”€ house_prices_final.png       # æœ€ç»ˆæ‹Ÿåˆç»“æœ
â””â”€â”€ README.md                    # æœ¬æ–‡æ¡£
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹åº“ï¼š

```bash
pip install numpy matplotlib scikit-learn
```

### 2. è¿è¡Œç¨‹åº

```bash
python linear_regression_demo.py
```

### 3. æŸ¥çœ‹ç»“æœ

ç¨‹åºä¼šè¾“å‡ºï¼š
- æ•°æ®ç»Ÿè®¡ä¿¡æ¯
- æ•°å­¦æ¦‚å¿µè§£é‡Š
- æ¨¡å‹è®­ç»ƒè¿‡ç¨‹
- é¢„æµ‹ç»“æœ
- å¹¶ç”Ÿæˆ4å¼ å¯è§†åŒ–å›¾è¡¨

---

## ğŸ“– æ ¸å¿ƒçŸ¥è¯†ç‚¹

### ä»€ä¹ˆæ˜¯çº¿æ€§å›å½’ï¼Ÿ

çº¿æ€§å›å½’ç”¨ä¸€æ¡ç›´çº¿ï¼ˆæˆ–è¶…å¹³é¢ï¼‰æ¥æ‹Ÿåˆæ•°æ®ï¼Œç”¨äºé¢„æµ‹è¿ç»­å€¼ã€‚

**æ•°å­¦å…¬å¼ï¼š**
```
y = wx + b
```

- `y`ï¼šé¢„æµ‹å€¼ï¼ˆå¦‚æˆ¿ä»·ï¼‰
- `x`ï¼šè¾“å…¥ç‰¹å¾ï¼ˆå¦‚é¢ç§¯ï¼‰
- `w`ï¼šæƒé‡/æ–œç‡ï¼ˆé¢ç§¯æ¯å¢åŠ 1å•ä½ï¼Œæˆ¿ä»·å¢åŠ å¤šå°‘ï¼‰
- `b`ï¼šåç½®/æˆªè·ï¼ˆåŸºç¡€ä»·æ ¼ï¼‰

### æœºå™¨å­¦ä¹ çš„3ä¸ªæ­¥éª¤

```python
# 1. å‡†å¤‡æ•°æ®
X = [[50], [60], [70], [80], [90], [100]]  # é¢ç§¯
y = [150, 180, 210, 240, 270, 300]         # æˆ¿ä»·

# 2. è®­ç»ƒæ¨¡å‹
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X, y)

# 3. åšå‡ºé¢„æµ‹
predicted = model.predict([[95]])  # é¢„æµ‹95å¹³ç±³çš„æˆ¿ä»·
print(predicted)  # è¾“å‡º: [285.]
```

---

## ğŸ“ è¯¦ç»†æ•™ç¨‹

### æ­¥éª¤1ï¼šè§‚å¯Ÿæ•°æ®

é¦–å…ˆå¯è§†åŒ–æ•°æ®ï¼Œçœ‹çœ‹ç‰¹å¾å’Œç›®æ ‡å€¼ä¹‹é—´æ˜¯ä»€ä¹ˆå…³ç³»ã€‚

**å…³é”®è§‚å¯Ÿï¼š**
- é¢ç§¯è¶Šå¤§ï¼Œæˆ¿ä»·è¶Šé«˜ âœ“
- å‘ˆç°çº¿æ€§å…³ç³»ï¼ˆè¿‘ä¼¼ä¸€æ¡ç›´çº¿ï¼‰âœ“
- é€‚åˆç”¨çº¿æ€§å›å½’ï¼âœ“

### æ­¥éª¤2ï¼šæ‰‹åŠ¨å°è¯•å‚æ•°

å°è¯•ä¸åŒçš„ `w` å’Œ `b`ï¼Œçœ‹çœ‹å“ªä¸ªæ‹Ÿåˆæœ€å¥½ã€‚

**å°è¯•1ï¼š** w=3, b=0
- é¢„æµ‹å€¼ï¼š[150, 180, 210, ...]
- MSEï¼š0.00 âœ“ å®Œç¾ï¼

**å°è¯•2ï¼š** w=2.5, b=50
- é¢„æµ‹å€¼ï¼š[175, 200, 225, ...]
- MSEï¼š187.50 âœ— è¯¯å·®è¾ƒå¤§

### æ­¥éª¤3ï¼šè‡ªåŠ¨è®­ç»ƒ

ä½¿ç”¨ `scikit-learn` è‡ªåŠ¨æ‰¾åˆ°æœ€ä¼˜å‚æ•°ï¼š

```python
model.fit(X, y)
print(f"w = {model.coef_[0]}")      # 3.0
print(f"b = {model.intercept_}")    # 0.0
```

**åŸç†ï¼šæ¢¯åº¦ä¸‹é™**

æƒ³è±¡ä½ åœ¨å±±ä¸Šï¼Œæƒ³ä¸‹å±±åˆ°æœ€ä½ç‚¹ï¼š
- **å±±çš„é«˜åº¦** = æŸå¤±å‡½æ•°å€¼ï¼ˆMSEï¼‰
- **ä½ çš„ä½ç½®** = å½“å‰çš„å‚æ•° w, b
- **æ¢¯åº¦** = å¡åº¦æœ€é™¡çš„æ–¹å‘
- **æ¢¯åº¦ä¸‹é™** = æ²¿æ¢¯åº¦åæ–¹å‘èµ°ï¼Œç›´åˆ°æœ€ä½ç‚¹

---

## ğŸ”¢ æ•°å­¦å…¬å¼è¯¦è§£

### å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰

**ä¸ºä»€ä¹ˆéœ€è¦æŸå¤±å‡½æ•°ï¼Ÿ**
- é‡åŒ–é¢„æµ‹æœ‰å¤š"é”™"
- ç»™æœºå™¨ä¸€ä¸ªä¼˜åŒ–ç›®æ ‡

**å…¬å¼ï¼š**
```
MSE = (1/n) Ã— Î£(çœŸå®å€¼ - é¢„æµ‹å€¼)Â²
```

**ä¸ºä»€ä¹ˆè¦å¹³æ–¹ï¼Ÿ**
1. æ¶ˆé™¤è´Ÿå·ï¼ˆ-5Â² = 25ï¼Œä¸ä¼šæ­£è´ŸæŠµæ¶ˆï¼‰
2. æ”¾å¤§å¤§è¯¯å·®ï¼ˆ10Â² = 100ï¼Œæ¯” 2Â² = 4 å¤§25å€ï¼‰
3. å¯å¾®åˆ†ï¼ˆæ–¹ä¾¿è®¡ç®—å¯¼æ•°ï¼‰

**Pythonå®ç°ï¼š**
```python
def calculate_loss(y_true, y_pred):
    squared_errors = (y_true - y_pred) ** 2
    mse = np.sum(squared_errors) / len(y_true)
    return mse
```

### æ¢¯åº¦ä¸‹é™

**ç›´è§‚ç†è§£ï¼š**

```
åˆå§‹åŒ–: w = random, b = random
å¾ªç¯:
    1. è®¡ç®—é¢„æµ‹å€¼: y_pred = w * x + b
    2. è®¡ç®—æŸå¤±: loss = MSE(y, y_pred)
    3. è®¡ç®—æ¢¯åº¦: dw = âˆ‚loss/âˆ‚w, db = âˆ‚loss/âˆ‚b
    4. æ›´æ–°å‚æ•°:
       w = w - learning_rate Ã— dw
       b = b - learning_rate Ã— db
ç›´åˆ°: loss ä¸å†å‡å°
```

**ç±»æ¯”ï¼š**
- å­¦ä¹ ç‡ = æ­¥é•¿ï¼ˆæ¯æ¬¡èµ°å¤šè¿œï¼‰
- å¤ªå¤§ï¼šå¯èƒ½è·¨è¿‡æœ€ä½ç‚¹
- å¤ªå°ï¼šæ”¶æ•›å¾ˆæ…¢

---

## ğŸ’¡ å®ç”¨æŠ€å·§

### 1. æŸ¥çœ‹æ¨¡å‹æ€§èƒ½

```python
# RÂ²å¾—åˆ†ï¼ˆ1.0è¡¨ç¤ºå®Œç¾ï¼‰
print(model.score(X, y))  # 1.0

# å‡æ–¹è¯¯å·®
from sklearn.metrics import mean_squared_error
y_pred = model.predict(X)
mse = mean_squared_error(y, y_pred)
print(f"MSE: {mse}")
```

### 2. å¤„ç†å¤šä¸ªç‰¹å¾

```python
# å¤šå…ƒçº¿æ€§å›å½’
X = [[50, 2],      # [é¢ç§¯, æˆ¿é—´æ•°]
     [60, 2],
     [70, 3],
     [80, 3]]

y = [150, 180, 210, 240]

model.fit(X, y)
print(f"æƒé‡: {model.coef_}")      # [é¢ç§¯æƒé‡, æˆ¿é—´æ•°æƒé‡]
print(f"åç½®: {model.intercept_}")
```

### 3. æ•°æ®æ ‡å‡†åŒ–ï¼ˆé‡è¦ï¼ï¼‰

å½“ç‰¹å¾é‡çº²ä¸åŒæ—¶ï¼Œå¿…é¡»æ ‡å‡†åŒ–ï¼š

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

model.fit(X_scaled, y)
```

---

## ğŸ“Š æ¨¡å‹è¯„ä¼°

### å¸¸ç”¨è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| **MSE** | å‡æ–¹è¯¯å·® | æƒ©ç½šå¤§è¯¯å·® |
| **MAE** | å¹³å‡ç»å¯¹è¯¯å·® | æ˜“äºç†è§£ |
| **RÂ²** | å†³å®šç³»æ•° | è§£é‡Šæ¨¡å‹æ‹Ÿåˆåº¦ |

### ä»£ç ç¤ºä¾‹

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.2f}")
print(f"MAE: {mae:.2f}")
print(f"RÂ²: {r2:.2f}")
```

---

## ğŸ¯ æ‰©å±•ç»ƒä¹ 

### ç»ƒä¹ 1ï¼šä¿®æ”¹æ•°æ®

å°è¯•ä¿®æ”¹ `linear_regression_demo.py` ä¸­çš„æ•°æ®ï¼š

```python
# æ·»åŠ ä¸€äº›å™ªå£°
X = np.array([50, 60, 70, 80, 90, 100])
y = np.array([155, 178, 205, 242, 268, 305])  # ä¸å®Œç¾çº¿æ€§
```

çœ‹çœ‹æ¨¡å‹èƒ½å¦æ‰¾åˆ°æ‹Ÿåˆæœ€å¥½çš„ç›´çº¿ï¼Ÿ

### ç»ƒä¹ 2ï¼šçœŸå®æ•°æ®é›†

ä½¿ç”¨çœŸå®æˆ¿ä»·æ•°æ®ï¼š

```bash
# ä¸‹è½½æ•°æ®é›†
wget https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv
```

### ç»ƒä¹ 3ï¼šå¤šç‰¹å¾é¢„æµ‹

æ·»åŠ æ›´å¤šç‰¹å¾ï¼š
- æˆ¿é—´æ•°é‡
- æˆ¿é¾„
- åœ°æ®µç­‰çº§
- åˆ°å¸‚ä¸­å¿ƒè·ç¦»

**æç¤ºï¼š** ä½¿ç”¨ `pandas` è¯»å–æ•°æ®

### ç»ƒä¹ 4ï¼šå¯è§†åŒ–æ¢¯åº¦ä¸‹é™

å°è¯•è‡ªå·±å®ç°æ¢¯åº¦ä¸‹é™ï¼Œå¹¶ç”»å‡ºæŸå¤±å‡½æ•°éšè¿­ä»£æ¬¡æ•°çš„å˜åŒ–ï¼š

```python
losses = []
for i in range(100):
    # è®¡ç®—æ¢¯åº¦
    # æ›´æ–°å‚æ•°
    # è®°å½•æŸå¤±
    losses.append(current_loss)

plt.plot(losses)
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.show()
```

---

## ğŸ”— ç›¸å…³èµ„æº

### æ¨èé˜…è¯»

- **[scikit-learnå®˜æ–¹æ–‡æ¡£](https://scikit-learn.org/stable/modules/linear_model.html)**
- **[æœºå™¨å­¦ä¹ å®æˆ˜](https://www.manning.com/books/machine-learning-in-action)**
- **[å´æ©è¾¾æœºå™¨å­¦ä¹ è¯¾ç¨‹](https://www.coursera.org/learn/machine-learning)**

### æ•°å­¦åŸºç¡€

- **[Khan Academy - ç»Ÿè®¡å­¦](https://www.khanacademy.org/math/statistics-probability)**ï¼ˆä¸­æ–‡ç‰ˆï¼‰
- **[3Blue1Brown - çº¿æ€§ä»£æ•°æœ¬è´¨](https://www.bilibili.com/video/BV1ys411472E)**
- **[StatQuestç³»åˆ—](https://www.youtube.com/c/StatQuestwithJoshStarmer)**ï¼ˆç”ŸåŠ¨æœ‰è¶£ï¼‰

### å®æˆ˜é¡¹ç›®

- Kaggleç«èµ›ï¼š[House Prices - Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)
- æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†ï¼ˆå·²å†…ç½®åœ¨sklearnä¸­ï¼‰

---

## ğŸ¤” å¸¸è§é—®é¢˜

### Q1: ä»€ä¹ˆæ—¶å€™ç”¨çº¿æ€§å›å½’ï¼Ÿ

**A:** å½“æ»¡è¶³ä»¥ä¸‹æ¡ä»¶æ—¶ï¼š
- ç›®æ ‡æ˜¯é¢„æµ‹è¿ç»­å€¼ï¼ˆå¦‚ä»·æ ¼ã€æ¸©åº¦ã€é”€é‡ï¼‰
- ç‰¹å¾å’Œç›®æ ‡ä¹‹é—´å¤§è‡´å‘ˆçº¿æ€§å…³ç³»
- æ•°æ®é‡ä¸å¤ªå¤§ï¼ˆ< 10ä¸‡æ ·æœ¬ï¼‰

### Q2: çº¿æ€§å›å½’ vs é€»è¾‘å›å½’ï¼Ÿ

**A:**
- **çº¿æ€§å›å½’**ï¼šé¢„æµ‹è¿ç»­å€¼ï¼ˆæˆ¿ä»·ã€æ¸©åº¦ï¼‰
- **é€»è¾‘å›å½’**ï¼šé¢„æµ‹ç±»åˆ«ï¼ˆæ˜¯/å¦ï¼Œ1/0ï¼‰

### Q3: æ¨¡å‹è¿‡æ‹Ÿåˆæ€ä¹ˆåŠï¼Ÿ

**A:** ä½¿ç”¨æ­£åˆ™åŒ–ï¼š
```python
# L1æ­£åˆ™åŒ–ï¼ˆLassoï¼‰
from sklearn.linear_model import Lasso
model = Lasso(alpha=0.1)

# L2æ­£åˆ™åŒ–ï¼ˆRidgeï¼‰
from sklearn.linear_model import Ridge
model = Ridge(alpha=0.1)

# å¼¹æ€§ç½‘ï¼ˆElasticNetï¼‰
from sklearn.linear_model import ElasticNet
model = ElasticNet(alpha=0.1, l1_ratio=0.5)
```

### Q4: å¦‚ä½•å¤„ç†ç¼ºå¤±å€¼ï¼Ÿ

**A:**
```python
# åˆ é™¤ç¼ºå¤±å€¼
X = X.dropna()

# å¡«å……ç¼ºå¤±å€¼
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)
```

---

## ğŸ“ˆ ä¸‹ä¸€æ­¥å­¦ä¹ 

å®Œæˆæœ¬é¡¹ç›®åï¼Œä½ å¯ä»¥ç»§ç»­å­¦ä¹ ï¼š

### ç®—æ³•è·¯çº¿
1. âœ… çº¿æ€§å›å½’ â† **å½“å‰**
2. â¬œ é€»è¾‘å›å½’ï¼ˆåˆ†ç±»é—®é¢˜ï¼‰
3. â¬œ å†³ç­–æ ‘ï¼ˆéçº¿æ€§é—®é¢˜ï¼‰
4. â¬œ éšæœºæ£®æ—ï¼ˆé›†æˆå­¦ä¹ ï¼‰
5. â¬œ ç¥ç»ç½‘ç»œï¼ˆæ·±åº¦å­¦ä¹ ï¼‰

### æŠ€èƒ½æå‡
- âœ… æ•°æ®æ¢ç´¢å’Œå¯è§†åŒ–
- â¬œ ç‰¹å¾å·¥ç¨‹
- â¬œ æ¨¡å‹è¯„ä¼°å’Œè°ƒä¼˜
- â¬œ äº¤å‰éªŒè¯
- â¬œ è¶…å‚æ•°è°ƒä¼˜

---

## ğŸ“ æ€»ç»“

### ä½ å·²ç»å­¦ä¼šï¼š
- âœ… çº¿æ€§å›å½’çš„åŸºæœ¬åŸç†
- âœ… å‡å€¼ã€æ±‚å’Œç¬¦å·ã€MSEã€æ¢¯åº¦ä¸‹é™
- âœ… ä½¿ç”¨ scikit-learn è®­ç»ƒæ¨¡å‹
- âœ… è¯„ä¼°æ¨¡å‹æ€§èƒ½

### æœºå™¨å­¦ä¹ çš„æœ¬è´¨ï¼š
```
æ•°æ® + æ¨¡å‹ + è®­ç»ƒ = é¢„æµ‹èƒ½åŠ›
```

### è®°ä½ï¼š
- ğŸ¯ **ç†è§£æ¯”æ¨å¯¼é‡è¦** - å…ˆæŒæ¡æ¦‚å¿µå’Œç›´è§‰
- ğŸ¯ **å®è·µæ¯”ç†è®ºé‡è¦** - å¤šå†™ä»£ç ï¼Œå¤šåŠ¨æ‰‹
- ğŸ¯ **åº”ç”¨æ¯”æ•°å­¦é‡è¦** - 70%çš„åœºæ™¯ç”¨ä¸åˆ°é«˜æ·±æ•°å­¦

---

## ğŸ“§ åé¦ˆä¸äº¤æµ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿ï¼š
- æIssue
- å‘èµ·Pull Request
- åˆ†äº«ä½ çš„å­¦ä¹ å¿ƒå¾—

---

## ğŸ“„ è®¸å¯è¯

MIT License - è‡ªç”±ä½¿ç”¨å’Œåˆ†äº«

---

**Happy Learning! ğŸ‰**

> "æœºå™¨å­¦ä¹ ä¸æ˜¯é­”æ³•ï¼Œå®ƒåªæ˜¯ä»æ•°æ®ä¸­å¯»æ‰¾æ¨¡å¼çš„æ•°å­¦å·¥å…·ã€‚"
