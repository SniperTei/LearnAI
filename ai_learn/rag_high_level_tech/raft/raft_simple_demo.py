"""
ç®€åŒ–ç‰ˆRAFT (Retrieval-Augmented Fine Tuning) å®ç°
================================================

è¿™æ˜¯ä¸€ä¸ªæ•™è‚²æ€§è´¨çš„ç®€åŒ–å®ç°ï¼Œç”¨äºç†è§£RAFTçš„æ ¸å¿ƒæ¦‚å¿µã€‚
å®é™…ç”Ÿäº§ç¯å¢ƒéœ€è¦æ›´å¤æ‚çš„å®ç°å’Œæ›´å¤šä¼˜åŒ–ã€‚

ä½œè€…: Claude Code Assistant
æ—¥æœŸ: 2026-01-27
"""

import random
from typing import List, Dict, Tuple
from dataclasses import dataclass
import json


# ============================================================================
# æ•°æ®ç»“æ„å®šä¹‰
# ============================================================================

@dataclass
class Document:
    """æ–‡æ¡£æ•°æ®ç»“æ„"""
    id: str
    content: str
    is_relevant: bool  # æ˜¯å¦ä¸é—®é¢˜ç›¸å…³


@dataclass
class RaftSample:
    """RAFTè®­ç»ƒæ ·æœ¬"""
    question: str
    documents: List[Document]
    answer: str
    citations: List[str]


# ============================================================================
# æ¨¡æ‹Ÿæ•°æ®é›†
# ============================================================================

def create_sample_dataset() -> List[Document]:
    """
    åˆ›å»ºç¤ºä¾‹æ–‡æ¡£åº“
    å®é™…åº”ç”¨ä¸­åº”ä»æ–‡ä»¶æˆ–æ•°æ®åº“åŠ è½½
    """
    documents = [
        # ç›¸å…³æ–‡æ¡£ï¼ˆå…³äºRAGï¼‰
        Document("D1", "RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ä¸€ç§ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯ã€‚", True),
        Document("D2", "RAGé€šè¿‡ä»å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚", True),
        Document("D3", "RAFTæ˜¯RAGçš„ä¸€ç§é«˜çº§æŠ€æœ¯ï¼Œé€šè¿‡å¾®è°ƒæ¨¡å‹æå‡æŠ—å¹²æ‰°èƒ½åŠ›ã€‚", True),
        Document("D4", "Embeddingå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œä½¿è¯­ä¹‰ç›¸ä¼¼çš„æ–‡æœ¬åœ¨å‘é‡ç©ºé—´ä¸­è·ç¦»æ›´è¿‘ã€‚", True),
        Document("D5", "å‘é‡æ•°æ®åº“å¦‚Chromaã€Pineconeç”¨äºå­˜å‚¨å’Œæ£€ç´¢æ–‡æ¡£å‘é‡ã€‚", True),

        # å¹²æ‰°æ–‡æ¡£ï¼ˆå…³äºå…¶ä»–ä¸»é¢˜ï¼‰
        Document("D6", "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•è€Œé—»åã€‚", False),
        Document("D7", "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ã€‚", False),
        Document("D8", "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹ã€‚", False),
        Document("D9", "JavaScriptä¸»è¦ç”¨äºWebå¼€å‘ï¼Œå¯ä»¥åœ¨æµè§ˆå™¨ä¸­è¿è¡Œã€‚", False),
        Document("D10", "SQLæ˜¯ç”¨äºç®¡ç†å’ŒæŸ¥è¯¢å…³ç³»æ•°æ®åº“çš„è¯­è¨€ã€‚", False),
        Document("D11", "Dockeræ˜¯ä¸€ä¸ªå®¹å™¨åŒ–å¹³å°ï¼Œå¯ä»¥æ‰“åŒ…åº”ç”¨ç¨‹åºåŠå…¶ä¾èµ–é¡¹ã€‚", False),
        Document("D12", "Gitæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œç”¨äºè·Ÿè¸ªä»£ç å˜åŒ–ã€‚", False),
    ]
    return documents


def create_training_samples() -> List[RaftSample]:
    """
    åˆ›å»ºè®­ç»ƒæ ·æœ¬
    å®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨Oracleæ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰ç”Ÿæˆç­”æ¡ˆ
    """
    samples = [
        RaftSample(
            question="ä»€ä¹ˆæ˜¯RAGï¼Ÿ",
            documents=create_sample_dataset()[:8],  # åŒ…å«ç›¸å…³å’Œå¹²æ‰°æ–‡æ¡£
            answer="æ ¹æ®æ–‡æ¡£[D1]å’Œ[D2]ï¼ŒRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ä¸€ç§ç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯ã€‚å®ƒé€šè¿‡ä»å¤–éƒ¨çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚",
            citations=["D1", "D2"]
        ),
        RaftSample(
            question="RAFTæ˜¯ä»€ä¹ˆï¼Ÿ",
            documents=create_sample_dataset()[:8],
            answer="æ ¹æ®æ–‡æ¡£[D3]ï¼ŒRAFTæ˜¯RAGçš„ä¸€ç§é«˜çº§æŠ€æœ¯ï¼Œé€šè¿‡å¾®è°ƒæ¨¡å‹æå‡æŠ—å¹²æ‰°èƒ½åŠ›ã€‚",
            citations=["D3"]
        ),
        RaftSample(
            question="ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“ï¼Ÿ",
            documents=create_sample_dataset(),
            answer="æ ¹æ®æ–‡æ¡£[D5]ï¼Œå‘é‡æ•°æ®åº“å¦‚Chromaã€Pineconeç”¨äºå­˜å‚¨å’Œæ£€ç´¢æ–‡æ¡£å‘é‡ã€‚",
            citations=["D5"]
        ),
    ]
    return samples


# ============================================================================
# RAFTæ ¸å¿ƒåŠŸèƒ½
# ============================================================================

class RaftTrainer:
    """RAFTè®­ç»ƒå™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰"""

    def __init__(self):
        self.prompt_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚è¯·ä»”ç»†é˜…è¯»æä¾›çš„æ–‡æ¡£ï¼Œå¹¶å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. ä»…åŸºäºæä¾›çš„æ–‡æ¡£å›ç­”é—®é¢˜
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜"æä¾›çš„æ–‡æ¡£ä¸­æ²¡æœ‰åŒ…å«è¯¥é—®é¢˜çš„ç­”æ¡ˆ"
3. å›ç­”æ—¶å¼•ç”¨ä½¿ç”¨çš„æ–‡æ¡£ï¼Œæ ¼å¼ä¸º[æ–‡æ¡£ID]
4. å¿½ç•¥ä¸é—®é¢˜æ— å…³çš„æ–‡æ¡£

æ–‡æ¡£ï¼š
{documents}

é—®é¢˜ï¼š{question}

ç­”æ¡ˆï¼š"""

    def format_documents(self, documents: List[Document]) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£"""
        return "\n\n".join([
            f"[{doc.id}] {doc.content}"
            for doc in documents
        ])

    def format_training_sample(self, sample: RaftSample) -> Tuple[str, str]:
        """
        æ ¼å¼åŒ–è®­ç»ƒæ ·æœ¬

        è¿”å›: (è¾“å…¥æ–‡æœ¬, ç›®æ ‡è¾“å‡º)
        """
        docs_text = self.format_documents(sample.documents)

        input_text = self.prompt_template.format(
            documents=docs_text,
            question=sample.question
        )

        target_output = sample.answer

        return input_text, target_output

    def prepare_dataset(self, samples: List[RaftSample]) -> List[Tuple[str, str]]:
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®é›†

        å®é™…åº”ç”¨ä¸­åº”è¯¥ï¼š
        1. æ·»åŠ æ›´å¤šæ ·æœ¬
        2. ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆä¸åŒå¹²æ‰°æ–‡æ¡£ç»„åˆï¼‰
        3. åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
        """
        dataset = []
        for sample in samples:
            input_text, output = self.format_training_sample(sample)
            dataset.append((input_text, output))
        return dataset

    def train(self, dataset: List[Tuple[str, int]], epochs: int = 3):
        """
        è®­ç»ƒæ¨¡å‹ï¼ˆç®€åŒ–ç‰ˆ - ä»…æ¼”ç¤ºæµç¨‹ï¼‰

        å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨transformers + PEFTè¿›è¡Œå¾®è°ƒï¼š
        ```python
        from transformers import AutoModelForCausalLM, Trainer
        from peft import LoraConfig, get_peft_model

        model = AutoModelForCausalLM.from_pretrained("base_model")
        lora_config = LoraConfig(r=8, lora_alpha=32, ...)
        model = get_peft_model(model, lora_config)

        trainer = Trainer(model=model, train_dataset=dataset)
        trainer.train()
        ```
        """
        print(f"ğŸš€ å¼€å§‹RAFTè®­ç»ƒï¼ˆç®€åŒ–ç‰ˆæ¼”ç¤ºï¼‰")
        print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬æ•°: {len(dataset)}")
        print(f"ğŸ”„ è®­ç»ƒè½®æ•°: {epochs}")

        for epoch in range(epochs):
            print(f"\n--- Epoch {epoch + 1}/{epochs} ---")

            for i, (input_text, output) in enumerate(dataset):
                print(f"\næ ·æœ¬ {i + 1}:")
                question_line = input_text.split('é—®é¢˜ï¼š')[1].split('\n')[0]
                print(f"é—®é¢˜: {question_line}")
                print(f"ç›®æ ‡ç­”æ¡ˆ: {output[:100]}...")

                # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
                # å®é™…åº”ç”¨ä¸­è¿™é‡Œæ˜¯æ¨¡å‹çš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­
                print("âœ… è®­ç»ƒæ­¥éª¤å®Œæˆ")

        print("\nâœ¨ è®­ç»ƒå®Œæˆï¼")


class RaftInference:
    """RAFTæ¨ç†å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰"""

    def __init__(self, model_path: str = None):
        """
        åˆå§‹åŒ–æ¨ç†å™¨

        å®é™…åº”ç”¨ä¸­åº”è¯¥åŠ è½½å¾®è°ƒåçš„æ¨¡å‹ï¼š
        ```python
        from transformers import AutoModelForCausalLM, AutoTokenizer
        from peft import PeftModel

        base_model = AutoModelForCausalLM.from_pretrained("base_model")
        tokenizer = AutoTokenizer.from_pretrained("base_model")

        if model_path:
            model = PeftModel.from_pretrained(base_model, model_path)
        ```
        """
        self.prompt_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚è¯·ä»”ç»†é˜…è¯»æä¾›çš„æ–‡æ¡£ï¼Œå¹¶å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. ä»…åŸºäºæä¾›çš„æ–‡æ¡£å›ç­”é—®é¢˜
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜"æä¾›çš„æ–‡æ¡£ä¸­æ²¡æœ‰åŒ…å«è¯¥é—®é¢˜çš„ç­”æ¡ˆ"
3. å›ç­”æ—¶å¼•ç”¨ä½¿ç”¨çš„æ–‡æ¡£ï¼Œæ ¼å¼ä¸º[æ–‡æ¡£ID]
4. å¿½ç•¥ä¸é—®é¢˜æ— å…³çš„æ–‡æ¡£

æ–‡æ¡£ï¼š
{documents}

é—®é¢˜ï¼š{question}

ç­”æ¡ˆï¼š"""

    def format_documents(self, documents: List[Document]) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£"""
        return "\n\n".join([
            f"[{doc.id}] {doc.content}"
            for doc in documents
        ])

    def retrieve_documents(self, question: str, all_docs: List[Document], top_k: int = 8) -> List[Document]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆç®€åŒ–ç‰ˆ - å®é™…åº”ä½¿ç”¨å‘é‡æ£€ç´¢ï¼‰

        å®é™…åº”ç”¨ä¸­åº”è¯¥ï¼š
        1. å¯¹é—®é¢˜è¿›è¡ŒEmbedding
        2. åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢
        3. è¿”å›top-kç›¸å…³æ–‡æ¡£ + ä¸€äº›å¹²æ‰°æ–‡æ¡£
        """
        # ç®€åŒ–ç‰ˆï¼šéšæœºè¿”å›ä¸€äº›æ–‡æ¡£
        # å®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢
        return random.sample(all_docs, min(top_k, len(all_docs)))

    def generate_answer(self, question: str, documents: List[Document]) -> str:
        """
        ç”Ÿæˆç­”æ¡ˆï¼ˆç®€åŒ–ç‰ˆ - ä»…æ¼”ç¤ºæµç¨‹ï¼‰

        å®é™…åº”ç”¨ä¸­åº”è¯¥ï¼š
        ```python
        inputs = tokenizer(prompt, return_tensors="pt")
        outputs = model.generate(**inputs, max_new_tokens=256)
        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)
        ```
        """
        docs_text = self.format_documents(documents)
        prompt = self.prompt_template.format(
            documents=docs_text,
            question=question
        )

        # ç®€åŒ–ç‰ˆï¼šè¿”å›æ¨¡æ‹Ÿç­”æ¡ˆ
        # å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹ç”Ÿæˆ
        relevant_docs = [doc for doc in documents if doc.is_relevant]

        if relevant_docs:
            citations = ", ".join([f"[{doc.id}]" for doc in relevant_docs])
            answer = f"æ ¹æ®æ–‡æ¡£{citations}ï¼Œè¿™æ˜¯é—®é¢˜çš„ç­”æ¡ˆã€‚"
        else:
            answer = "æä¾›çš„æ–‡æ¡£ä¸­æ²¡æœ‰åŒ…å«è¯¥é—®é¢˜çš„ç­”æ¡ˆã€‚"

        return answer

    def query(self, question: str, document_store: List[Document]) -> Dict:
        """
        å®Œæ•´çš„æŸ¥è¯¢æµç¨‹
        """
        print(f"\nğŸ” æŸ¥è¯¢: {question}")

        # 1. æ£€ç´¢æ–‡æ¡£
        retrieved_docs = self.retrieve_documents(question, document_store)
        print(f"ğŸ“š æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªæ–‡æ¡£")

        # 2. ç”Ÿæˆç­”æ¡ˆ
        answer = self.generate_answer(question, retrieved_docs)
        print(f"ğŸ’¡ ç­”æ¡ˆ: {answer}")

        # 3. æå–å¼•ç”¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
        citations = self.extract_citations(answer)
        print(f"ğŸ“ å¼•ç”¨: {citations}")

        return {
            "question": question,
            "answer": answer,
            "citations": citations,
            "retrieved_docs": retrieved_docs
        }

    def extract_citations(self, answer: str) -> List[str]:
        """ä»ç­”æ¡ˆä¸­æå–å¼•ç”¨"""
        import re
        pattern = r'\[([^\]]+)\]'
        matches = re.findall(pattern, answer)
        return matches


# ============================================================================
# æ•°æ®ç”Ÿæˆå·¥å…·
# ============================================================================

class RaftDataGenerator:
    """RAFTè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨"""

    def __init__(self):
        pass

    def generate_oracle_answer(self, question: str, relevant_docs: List[Document]) -> str:
        """
        ä½¿ç”¨Oracleæ¨¡å‹ç”Ÿæˆç­”æ¡ˆ

        å®é™…åº”ç”¨ä¸­åº”è¯¥ï¼š
        ```python
        import openai
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{
                "role": "user",
                "content": f"åŸºäºè¿™äº›æ–‡æ¡£å›ç­”ï¼š{relevant_docs}\\né—®é¢˜ï¼š{question}"
            }]
        )
        return response.choices[0].message.content
        ```
        """
        # ç®€åŒ–ç‰ˆï¼šåŸºäºç›¸å…³æ–‡æ¡£ç”Ÿæˆç®€å•ç­”æ¡ˆ
        if not relevant_docs:
            return "æä¾›çš„æ–‡æ¡£ä¸­æ²¡æœ‰åŒ…å«è¯¥é—®é¢˜çš„ç­”æ¡ˆã€‚"

        citations = ", ".join([f"[{doc.id}]" for doc in relevant_docs])
        return f"æ ¹æ®æ–‡æ¡£{citations}ï¼Œè¿™æ˜¯å…³äºé—®é¢˜çš„ç­”æ¡ˆã€‚"

    def add_distractor_documents(self, relevant_docs: List[Document],
                                 all_docs: List[Document],
                                 num_distractors: int = 5) -> List[Document]:
        """
        æ·»åŠ å¹²æ‰°æ–‡æ¡£

        ç­–ç•¥ï¼š
        1. éšæœºé€‰æ‹©
        2. å›°éš¾è´Ÿæ ·æœ¬ï¼ˆè¯­ä¹‰ç›¸ä¼¼ä½†æ— å…³ï¼‰
        3. åŒé¢†åŸŸä¸åŒä¸»é¢˜
        """
        irrelevant_docs = [doc for doc in all_docs if not doc.is_relevant]

        if len(irrelevant_docs) < num_distractors:
            num_distractors = len(irrelevant_docs)

        distractors = random.sample(irrelevant_docs, num_distractors)

        # åˆå¹¶ç›¸å…³æ–‡æ¡£å’Œå¹²æ‰°æ–‡æ¡£
        all_retrieved = relevant_docs + distractors

        # æ‰“ä¹±é¡ºåº
        random.shuffle(all_retrieved)

        return all_retrieved

    def create_training_sample(self, question: str, all_docs: List[Document]) -> RaftSample:
        """
        åˆ›å»ºå•ä¸ªè®­ç»ƒæ ·æœ¬

        æµç¨‹ï¼š
        1. è¯†åˆ«ç›¸å…³æ–‡æ¡£
        2. ä½¿ç”¨Oracleç”Ÿæˆç­”æ¡ˆ
        3. æ·»åŠ å¹²æ‰°æ–‡æ¡£
        4. è¿”å›è®­ç»ƒæ ·æœ¬
        """
        # 1. è¯†åˆ«ç›¸å…³æ–‡æ¡£
        relevant_docs = [doc for doc in all_docs if doc.is_relevant]

        # 2. ç”Ÿæˆç­”æ¡ˆ
        answer = self.generate_oracle_answer(question, relevant_docs)

        # 3. æ·»åŠ å¹²æ‰°æ–‡æ¡£
        all_retrieved = self.add_distractor_documents(relevant_docs, all_docs)

        # 4. æå–å¼•ç”¨
        citations = [doc.id for doc in relevant_docs]

        return RaftSample(
            question=question,
            documents=all_retrieved,
            answer=answer,
            citations=citations
        )


# ============================================================================
# è¯„ä¼°å·¥å…·
# ============================================================================

class RaftEvaluator:
    """RAFTè¯„ä¼°å™¨"""

    @staticmethod
    def citation_accuracy(predicted_citations: List[str],
                         gold_citations: List[str]) -> float:
        """
        è®¡ç®—å¼•ç”¨å‡†ç¡®ç‡
        """
        if not gold_citations:
            return 1.0 if not predicted_citations else 0.0

        overlap = set(predicted_citations) & set(gold_citations)
        return len(overlap) / len(gold_citations)

    @staticmethod
    def distractor_rejection_rate(predicted_citations: List[str],
                                  distractor_ids: List[str]) -> float:
        """
        è®¡ç®—å¹²æ‰°æ–‡æ¡£æ’é™¤ç‡
        æˆåŠŸæ’é™¤å¹²æ‰°æ–‡æ¡£çš„æ¯”ä¾‹
        """
        if not distractor_ids:
            return 1.0

        cited = set(predicted_citations)
        distractors = set(distractor_ids)
        wrongly_cited = cited & distractors

        return 1 - (len(wrongly_cited) / len(distractors))

    def evaluate_sample(self, prediction: RaftSample, gold_standard: RaftSample) -> Dict:
        """
        è¯„ä¼°å•ä¸ªæ ·æœ¬
        """
        citation_acc = self.citation_accuracy(
            prediction.citations,
            gold_standard.citations
        )

        distractor_ids = [doc.id for doc in gold_standard.documents if not doc.is_relevant]
        rejection_rate = self.distractor_rejection_rate(
            prediction.citations,
            distractor_ids
        )

        return {
            "citation_accuracy": citation_acc,
            "distractor_rejection_rate": rejection_rate,
            "overall_score": (citation_acc + rejection_rate) / 2
        }


# ============================================================================
# ä¸»ç¨‹åºæ¼”ç¤º
# ============================================================================

def main():
    """ä¸»ç¨‹åº - æ¼”ç¤ºRAFTå®Œæ•´æµç¨‹"""

    print("=" * 80)
    print("RAFT (Retrieval-Augmented Fine Tuning) ç®€åŒ–ç‰ˆæ¼”ç¤º")
    print("=" * 80)

    # 1. å‡†å¤‡æ–‡æ¡£åº“
    print("\nğŸ“š å‡†å¤‡æ–‡æ¡£åº“...")
    document_store = create_sample_dataset()
    print(f"âœ… æ–‡æ¡£åº“åŒ…å« {len(document_store)} ä¸ªæ–‡æ¡£")

    # 2. åˆ›å»ºè®­ç»ƒæ•°æ®
    print("\nğŸ“ åˆ›å»ºè®­ç»ƒæ ·æœ¬...")
    data_generator = RaftDataGenerator()

    questions = [
        "ä»€ä¹ˆæ˜¯RAGï¼Ÿ",
        "RAFTæ˜¯ä»€ä¹ˆï¼Ÿ",
        "ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“ï¼Ÿ"
    ]

    training_samples = []
    for question in questions:
        sample = data_generator.create_training_sample(question, document_store)
        training_samples.append(sample)
        print(f"âœ… åˆ›å»ºæ ·æœ¬: {question}")

    # 3. è®­ç»ƒæ¨¡å‹
    print("\n" + "=" * 80)
    print("ğŸš€ å¼€å§‹è®­ç»ƒ")
    print("=" * 80)

    trainer = RaftTrainer()
    dataset = trainer.prepare_dataset(training_samples)
    trainer.train(dataset, epochs=2)

    # 4. ä¿å­˜è®­ç»ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
    print("\nğŸ’¾ ä¿å­˜è®­ç»ƒæ•°æ®...")
    train_data_json = []
    for sample in training_samples:
        train_data_json.append({
            "question": sample.question,
            "documents": [
                {"id": doc.id, "content": doc.content, "is_relevant": doc.is_relevant}
                for doc in sample.documents
            ],
            "answer": sample.answer,
            "citations": sample.citations
        })

    with open("/Users/zhengnan/Sniper/Developer/github/LearnAgent/ai_learn/rag_high_level_tech/raft_training_data.json", "w", encoding="utf-8") as f:
        json.dump(train_data_json, f, ensure_ascii=False, indent=2)
    print("âœ… è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: raft_training_data.json")

    # 5. æ¨ç†æ¼”ç¤º
    print("\n" + "=" * 80)
    print("ğŸ”® æ¨ç†æ¼”ç¤º")
    print("=" * 80)

    inference = RaftInference()

    test_questions = [
        "ä»€ä¹ˆæ˜¯RAGï¼Ÿ",
        "Pythonæ˜¯ä»€ä¹ˆï¼Ÿ"  # æ–‡æ¡£ä¸­æœ‰ç›¸å…³ä¿¡æ¯
    ]

    for question in test_questions:
        result = inference.query(question, document_store)

    # 6. è¯„ä¼°æ¼”ç¤º
    print("\n" + "=" * 80)
    print("ğŸ“Š è¯„ä¼°æ¼”ç¤º")
    print("=" * 80)

    evaluator = RaftEvaluator()

    # æ¨¡æ‹Ÿé¢„æµ‹ç»“æœ
    prediction = training_samples[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ ·æœ¬ä½œä¸ºç¤ºä¾‹

    # è¯„ä¼°
    metrics = evaluator.evaluate_sample(prediction, prediction)

    print(f"\nè¯„ä¼°ç»“æœ:")
    print(f"  å¼•ç”¨å‡†ç¡®ç‡: {metrics['citation_accuracy']:.2%}")
    print(f"  å¹²æ‰°æ–‡æ¡£æ’é™¤ç‡: {metrics['distractor_rejection_rate']:.2%}")
    print(f"  ç»¼åˆå¾—åˆ†: {metrics['overall_score']:.2%}")

    print("\n" + "=" * 80)
    print("âœ¨ æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)

    print("\nğŸ“– è¯´æ˜:")
    print("1. è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ•™è‚²æ€§å®ç°ï¼Œç”¨äºç†è§£RAFTçš„æ ¸å¿ƒæ¦‚å¿µ")
    print("2. å®é™…åº”ç”¨éœ€è¦:")
    print("   - çœŸå®çš„å‘é‡æ£€ç´¢ï¼ˆEmbedding + å‘é‡æ•°æ®åº“ï¼‰")
    print("   - ä½¿ç”¨transformers + PEFTè¿›è¡Œå®é™…å¾®è°ƒ")
    print("   - æ›´å¤§çš„è®­ç»ƒæ•°æ®é›†")
    print("   - ä½¿ç”¨Oracleæ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰ç”Ÿæˆé«˜è´¨é‡ç­”æ¡ˆ")
    print("3. å‚è€ƒæ–‡æ¡£ä¸­çš„ä»£ç æ³¨é‡Šäº†è§£å®Œæ•´çš„å®ç°ç»†èŠ‚")


if __name__ == "__main__":
    main()
