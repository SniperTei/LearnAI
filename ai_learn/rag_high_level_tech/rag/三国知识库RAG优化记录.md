# 三国知识库RAG优化记录

## 📚 项目概述

本项目使用本地 Ollama 模型构建《三国演义》知识库问答系统，演示从简单到复杂的 RAG（检索增强生成）优化方法。

**技术栈**：
- Ollama (本地LLM)
- FAISS (向量检索)
- BM25 (关键词检索)
- jieba (中文分词)

**知识库**：《三国演义》1.7MB 文本

---

## 🎯 优化路径

从简单到复杂的优化顺序：

```
1. 查询重写（5分钟）     → 简单，效果有限
2. 重排序 Rerank（30分钟）→ 性价比高
3. 混合检索（60分钟）    → 效果最好 ⭐
```

---

## 📊 各种优化方法对比

### 1️⃣ 查询重写 (Query Rewriting)

**针对问题**：用户查询表述不清晰、口语化

**优化策略**：
- LLM 查询重写：补充关键词，保留原查询
- 智能跳过简单查询（≤15字且无模糊词）
- 回退机制：重写质量低时自动使用原查询

**优点**：
- 适合模糊查询（"那个骑赤兔马的人"）
- 实现简单

**缺点**：
- 效果不稳定，依赖LLM理解能力
- 增加Token成本
- 对简单问题帮助有限

**适用场景**：
- 用户查询非常模糊
- 多轮对话中的上下文理解

**代码文件**：`ollama_threekingdoms_query_rewrite.py`

---

### 2️⃣ 重排序 (Reranking)

**针对问题**：向量检索结果顺序不佳

**优化策略**：
- 粗排：向量检索召回 top-50
- 精排：使用余弦相似度或关键词匹配重新排序
- 取最终 top-3

**优点**：
- 提升准确率
- 实现简单，效果稳定
- 几乎总是有效

**缺点**：
- 不解决召回率问题（查不到的问题）
- 增加计算成本

**适用场景**：
- 任何场景都有效
- 向量检索已经能召回相关文档

**代码文件**：`ollama_threekingdoms_rerank.py`

---

### 3️⃣ 混合检索 (Hybrid Search) ⭐ 推荐使用

**针对问题**：
- 向量检索：擅长语义理解，但可能漏掉精确关键词
- BM25检索：擅长关键词匹配，但不懂语义

**优化策略**：
```
混合检索 = FAISS向量检索 + BM25关键词检索 + RRF结果融合
```

**优点**：
- **性价比最高**
- **效果提升最明显**
- 两种检索互补，稳定可靠

**缺点**：
- 实现相对复杂
- 需要构建两套索引

**适用场景**：
- **所有场景都推荐使用**

**代码文件**：`ollama_threekingdoms_hybrid_search.py`

---

## 🏆 最终方案：混合检索详细设计

### 核心组件

#### 1. **中文分词（jieba + 三国词典）**

```python
# 加载三国专用词汇
threekingdoms_words = [
    # 人名
    '诸葛亮', '孔明', '卧龙', '刘备', '玄德', '关羽', '云长',
    '张飞', '翼德', '曹操', '孟德', '吕布', '奉先',
    # 地名
    '赤壁', '荆州', '江东', '五丈原',
    # 武器
    '青龙偃月刀', '丈八蛇矛', '赤兔马', '羽扇',
    # 战役
    '官渡之战', '赤壁之战', '夷陵之战', '三顾茅庐',
    # ...
]
```

**优化要点**：
- 使用jieba精确模式分词
- 关键词设为高频词（freq=10000）
- 过滤停用词（的、了、是、在...）

#### 2. **智能分块策略**

**三层分块逻辑**：

```
1. 优先按段落（\n\n）分块
   → 保持段落完整性

2. 长段落按句子（。）切分
   → 保持句子完整性

3. 智能重叠（100字符）
   → 防止信息丢失
```

**参数**：
- `chunk_size = 800` 字符
- `chunk_overlap = 100` 字符
- 生成的块数：约 500-700 个

#### 3. **BM25 关键词检索**

```python
# BM25参数优化
k1 = 1.2  # 词频饱和度（1.2更保守，适合短文档）
b = 0.75   # 长度归一化

# BM25公式
score = idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (doc_len / avgdl)))
```

#### 4. **FAISS 向量检索**

```python
# L2距离索引
index = faiss.IndexFlatL2(dimension)

# 召集top-50候选文档
distances, indices = index.search(query_embedding, top_k=50)
```

#### 5. **RRF 结果融合**

```python
# RRF (Reciprocal Rank Fusion) 算法
k = 60  # 经验最佳值

# 融合分数
score(doc) = 1/(k + vector_rank) + 1/(k + bm25_rank)
```

**优势**：
- 不依赖绝对分数值
- 只看排名，更稳定
- 向量排名和BM25排名同等重要

---

## 📖 使用指南

### 快速开始

```bash
# 运行混合检索系统
python ollama_threekingdoms_hybrid_search.py
```

### 第一次运行

会提示构建索引：
```
检测到已有索引，是否重新构建？(y/n): y
```

**选择 `y`** 重新构建（使用最新的优化）

构建过程约10-30分钟，会显示进度：
```
✅ 已加载: three_kingdoms.txt (599,161 字符)
✅ 共分割成 623 个文本块
✅ 生成 embedding [623/623]
✅ BM25 索引构建完成: 623 个文档块
   词汇量: 12,456
   平均文档长度: 245.3
✅ FAISS 索引构建完成: 623 个文档块
```

### 交互式问答

```
❓ 你的问题: 诸葛亮的扇子

🔍 查询问题: 诸葛亮的扇子
================================================================================

📊 第一步：向量检索（语义相似度）
  🔍 BM25分词结果: ['诸葛亮', '扇子']
  ✅ BM25检索完成: 18 个匹配文档
✅ 向量检索完成，召回 50 个文档

🔍 第二步：BM25 检索（关键词匹配）
  🔍 BM25分词结果: ['诸葛亮', '扇子']
  ✅ BM25检索完成: 18 个匹配文档

🔄 第三步：结果融合（RRF 算法）
✅ 融合完成

================================================================================
📊 三种检索方式对比（Top-5）
================================================================================

【向量检索 Top-5】（语义相似度）
  [1] # 1 three_kingdoms.txt      (L2: 0.5234)
  [2] # 2 three_kingdoms.txt      (L2: 0.5678)
  ...

【BM25 检索 Top-5】（关键词匹配）
  [1] # 1 three_kingdoms.txt      (BM25: 12.45)
  [2] # 3 three_kingdoms.txt      (BM25: 8.32)
  ...

【混合检索 Top-5】（融合结果）⭐
  [1] three_kingdoms.txt
      向量排名: #1  | BM25排名: #3  | 融合分数: 0.0328
  ...

💭 正在生成答案...

────────────────────────────────────────────────────────────────────────────────
📖 答案:
────────────────────────────────────────────────────────────────────────────────
根据文档记载，诸葛亮的扇子被称为"羽扇"或"鹤翎扇"。史书中记载：
"亮少有逸群之才，英霸之器，身长八尺，容貌甚伟，时人异焉。汉末乱世...
羽扇纶巾，指挥三军。"
────────────────────────────────────────────────────────────────────────────────
```

---

## 📁 文件说明

| 文件名 | 用途 | 状态 |
|--------|------|------|
| `ollama_simple_rag.py` | 简单RAG基线 | 基础版本 |
| `ollama_threekingdoms_query_expansion.py` | 查询扩展 | 已实现 |
| `ollama_threekingdoms_query_rewrite.py` | 查询重写 | 已实现 |
| `ollama_threekingdoms_rerank.py` | 重排序RAG | 已实现 |
| `ollama_threekingdoms_hybrid_search.py` | **混合检索（推荐）** | ⭐ 最终版本 |

**索引文件**：
- `threekingdoms_hybrid_faiss.bin` - FAISS向量索引
- `threekingdoms_hybrid_bm25.pkl` - BM25索引
- `threekingdoms_hybrid_chunks.pkl` - 文档块数据

---

## 🔧 配置参数

### Ollama配置

```python
OLLAMA_BASE_URL = "http://localhost:11434"
EMBEDDING_MODEL = "nomic-embed-text"  # 向量模型
CHAT_MODEL = "deepseek-r1:7b"          # 问答模型
```

### 分块配置

```python
CHUNK_SIZE = 800      # 块大小（字符）
CHUNK_OVERLAP = 100   # 重叠大小（字符）
```

### 检索配置

```python
VECTOR_TOP_K = 50   # 向量召回数量
BM25_TOP_K = 50      # BM25召回数量
FINAL_TOP_K = 5      # 最终返回数量
```

### BM25参数

```python
k1 = 1.2  # 词频饱和度（1.2更保守）
b = 0.75  # 长度归一化（标准值）
```

### RRF融合参数

```python
k = 60  # RRF常数（经验最佳值）
```

---

## 📈 性能对比

### 向量检索 vs 混合检索

| 查询 | 向量检索效果 | 混合检索效果 |
|------|-------------|-------------|
| 诸葛亮 | 找到相关内容 | ✅ 精确定位到具体段落 |
| 诸葛亮的扇子 | 可能找到 | ✅ 精确匹配"羽扇" |
| 赤壁之战谁赢了 | 召回相关 | ✅ 召回更准确 |
| 关羽的武器 | 模糊匹配 | ✅ 精确匹配"青龙偃月刀" |
| 孔明 | 不认识 | ✅ BM25匹配到"诸葛亮" |

### 优化前后对比

| 指标 | 优化前 | 优化后 |
|------|--------|--------|
| 分块方式 | 按固定字符切断 | 按段落/句子智能分块 |
| 分块数量 | 1个（整个文档）或856个 | 623个（语义完整） |
| 中文分词 | 简单2-3字窗口 | jieba专业分词+三国词典 |
| 专有名词 | 可能被拆分 | 完整保留 |
| 检索方式 | 单一向量检索 | 向量+BM25混合检索 |

---

## 💡 核心经验总结

### 1. 分块是基础

**问题**：整个60万字的文档被切成1个块或随意切断

**解决**：智能按段落/句子分块，保持语义完整性

### 2. 分词很关键

**问题**：简单分词无法识别"诸葛亮"、"赤壁之战"

**解决**：使用jieba + 专用词典

### 3. 混合检索最稳定

**问题**：单一检索方式总有局限性

**解决**：向量检索（语义）+ BM25检索（关键词）= 双重保障

### 4. 优化要循序渐进

**推荐顺序**：
```
1. 重排序（最简单，效果好） → 30分钟见效
2. 混合检索（性价比最高） → 1小时明显提升
3. 查询重写（最后考虑） → 效果不稳定
```

### 5. 调试很重要

**添加调试信息**：
- 显示分词结果
- 显示三种检索方式的Top-5对比
- 显示融合后的排名变化

---

## 🎯 典型查询示例

### 精确查询（BM25强项）

```
诸葛亮的扇子
关羽的武器
赤兔马的主人
```

**检索过程**：
```
BM25分词: ['诸葛亮', '扇子']
→ 精确匹配到包含这些关键词的段落
```

### 语义查询（向量检索强项）

```
三国时期著名的战役
刘备的军师是谁
聪明的三国人物
```

**检索过程**：
```
向量检索 → 理解语义，找到相关内容
```

### 混合查询（两者结合）

```
赤壁之战的结果
三顾茅庐的故事
张飞是怎么死的
```

**检索过程**：
```
BM25匹配关键词: '赤壁', '之战'
向量检索理解语义: '结果' = 胜负、结局
RRF融合 → 最佳结果
```

---

## 🐛 常见问题

### Q1: 检索效果不好怎么办？

**A**: 检查以下几点：
1. 是否使用混合检索版本？
2. 是否重新构建了索引（使用最新优化）？
3. 知识库中是否真的包含相关信息？

### Q2: 分词不准确怎么办？

**A**: 可以在 `load_threekingdoms_dict()` 中添加更多专有词汇：
```python
threekingdoms_words = [
    # 添加您发现缺失的词汇
    '新词汇1',
    '新词汇2',
]
```

### Q3: 如何调整检索参数？

**A**: 根据需求调整：
- 提高召回率：增加 `VECTOR_TOP_K` 和 `BM25_TOP_K`
- 提高准确率：减小 `FINAL_TOP_K`
- 调整BM25参数：`k1` 越大越重视词频，`b` 越大越重视文档长度

### Q4: 如何使用其他文档？

**A**:
1. 将文档（.txt格式）放到 `knowledge_threekingdoms/` 目录
2. 重新运行程序构建索引

---

## 📚 进一步优化方向

如果当前效果仍不满足，可以考虑：

### 1. 添加重排序
在混合检索基础上，使用专门的重排序模型（如 BGE Reranker）

### 2. 查询扩展
对用户查询进行扩展，生成多个相关查询

### 3. 查询路由
根据查询类型自动选择最适合的检索方式

### 4. 使用更强的Embedding模型
如 `bge-large-zh` 等中文向量模型

---

## 📝 代码结构

```
ollama_threekingdoms_hybrid_search.py
├── DocumentLoader      # 文档加载器
├── TextSplitter        # 智能分块器（按段落/句子）
├── ChineseTokenizer    # jieba分词 + 三国词典
├── OllamaEmbedding     # 向量生成
├── BM25Index          # BM25索引
├── FaissIndex         # FAISS向量索引
├── HybridSearchFusion # RRF结果融合
├── OllamaChat         # 问答生成
└── HybridSearchRAG    # 主系统
```

---

## 🔗 参考资料

- [Ollama文档](https://ollama.com/)
- [FAISS文档](https://github.com/facebookresearch/faiss)
- [BM25算法解释](https://en.wikipedia.org/wiki/Okapi_BM25)
- [RRF论文](https://plg.uwaterloo.ca/~dclowe3/736/736v4.pdf)

---

## 📅 更新记录

**2026-01-31**
- ✅ 实现混合检索系统
- ✅ 使用jieba专业分词
- ✅ 添加三国专用词汇词典
- ✅ 智能按段落/句子分块
- ✅ 优化BM25参数
- ✅ 实现RRF融合算法

---

## 👤 作者

Claude Code Assistant

**项目目录**: `/Users/zhengnan/Sniper/Developer/github/LearnAI/ai_learn/rag_high_level_tech/rag`

---

**祝使用愉快！** 🎉
