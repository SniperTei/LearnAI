"""
Ollama + Faiss + Query Rewrite æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ç³»ç»Ÿ
===================================================

ä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹ + Faiss + æŸ¥è¯¢é‡å†™æ„å»ºçš„æœ¬åœ°çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿã€‚
æ¼”ç¤º RAG é«˜æ•ˆå¬å›æ–¹æ³•ï¼šæŸ¥è¯¢é‡å†™ï¼ˆQuery Rewritingï¼‰

æŸ¥è¯¢é‡å†™æ–¹æ³•ï¼š
1. LLM æŸ¥è¯¢é‡å†™ - è®© LLM ç†è§£æ„å›¾å¹¶æ”¹å†™æŸ¥è¯¢
2. HyDE - ç”Ÿæˆå‡è®¾ç­”æ¡ˆï¼Œç”¨ç­”æ¡ˆå»æ£€ç´¢
3. Step-back - å°†å…·ä½“é—®é¢˜æŠ½è±¡æˆæ›´é«˜å±‚æ¬¡çš„é—®é¢˜

ç‰¹ç‚¹ï¼š
- å¯¹æ¯”ä¸åŒæŸ¥è¯¢é‡å†™æ–¹æ³•çš„æ•ˆæœ
- å¯è§†åŒ–å±•ç¤ºé‡å†™å‰åçš„æŸ¥è¯¢
- ä¸“é—¨é’ˆå¯¹æ¨¡ç³Šã€å¤æ‚é—®é¢˜ä¼˜åŒ–

ä½œè€…: Claude Code Assistant
æ—¥æœŸ: 2026-01-31
"""

import os
import json
import pickle
from typing import List, Dict, Tuple
from pathlib import Path
import re
import requests

import numpy as np
import faiss

# ============================================================================
# é…ç½®
# ============================================================================

OLLAMA_BASE_URL = "http://localhost:11434"
EMBEDDING_MODEL = "nomic-embed-text"
CHAT_MODEL = "deepseek-r1:7b"

DOCS_DIR = "knowledge_threekingdoms"  # æ”¹ç”¨ä¸‰å›½çŸ¥è¯†åº“
INDEX_PREFIX = "threekingdoms_query_rewrite"  # ç´¢å¼•å‰ç¼€ä¹Ÿæ”¹ä¸€ä¸‹é¿å…å†²çª
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50
COARSE_TOP_K = 50
FINAL_TOP_K = 3

# ============================================================================
# æŸ¥è¯¢é‡å†™å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# ============================================================================

class QueryRewriter:
    """æŸ¥è¯¢é‡å†™å™¨ - ä¼˜åŒ–æŸ¥è¯¢è´¨é‡ï¼ˆå¸¦ä¿æŠ¤æœºåˆ¶ï¼‰"""

    def __init__(self, method: str = "llm_rewrite", enable_fallback: bool = True):
        """
        Args:
            method: é‡å†™æ–¹æ³•
                - "llm_rewrite": LLM æŸ¥è¯¢é‡å†™ï¼ˆæ¨èï¼Œä¿å®ˆç­–ç•¥ï¼‰
                - "hyde": HyDE (Hypothetical Document Embeddings)
                - "step_back": Step-back æŠ½è±¡åŒ–
            enable_fallback: æ˜¯å¦å¯ç”¨å›é€€æœºåˆ¶ï¼ˆé‡å†™å¤±è´¥æ—¶ä½¿ç”¨åŸæŸ¥è¯¢ï¼‰
        """
        self.method = method
        self.base_url = OLLAMA_BASE_URL
        self.model = CHAT_MODEL
        self.enable_fallback = enable_fallback

    def _llm_rewrite(self, query: str) -> str:
        """
        LLM æŸ¥è¯¢é‡å†™ï¼ˆè¶…ä¿å®ˆç­–ç•¥ï¼‰

        åŸç†ï¼š
        1. å®Œæ•´ä¿ç•™åŸæŸ¥è¯¢
        2. åªæ·»åŠ 1-3ä¸ªè¡¥å……å…³é”®è¯
        3. ä¸è¿‡åº¦é‡å†™
        """
        prompt = f"""è¯·æ”¹è¿›ä»¥ä¸‹æœç´¢æŸ¥è¯¢ï¼Œè¾“å‡ºä¸€ä¸ªä¼˜åŒ–çš„æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚

åŸæŸ¥è¯¢ï¼š{query}

è¦æ±‚ï¼š
1. **å¿…é¡»åŒ…å«åŸæŸ¥è¯¢çš„å®Œæ•´å†…å®¹**ï¼ˆå¯ä»¥åœ¨å‰é¢æˆ–åé¢æ·»åŠ å…³é”®è¯ï¼‰
2. åªæ·»åŠ  1-3 ä¸ªç›¸å…³çš„è¡¥å……å…³é”®è¯ï¼ˆåŒä¹‰è¯ã€ç›¸å…³æœ¯è¯­ï¼‰
3. ç”¨ç©ºæ ¼åˆ†éš”å…³é”®è¯
4. ä¸è¦æ”¹å˜é—®é¢˜çš„æ ¸å¿ƒæ„æ€
5. ä¿æŒç®€æ´

ç¤ºä¾‹ï¼š
- "è¯¸è‘›äº®" â†’ "è¯¸è‘›äº® å­”æ˜ å§é¾™"
- "èµ¤å£ä¹‹æˆ˜" â†’ "èµ¤å£ä¹‹æˆ˜ å‘¨ç‘œ æ›¹æ“ å­™æƒ åˆ˜å¤‡"
- "æ€ä¹ˆåšçº¢çƒ§è‚‰" â†’ "æ€ä¹ˆåšçº¢çƒ§è‚‰ çƒ¹é¥ªæ–¹æ³• æ­¥éª¤"

åªè¾“å‡ºæ”¹è¿›åçš„æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼š"""

        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.1, "num_predict": 80}
                },
                timeout=60
            )

            if response.status_code == 200:
                rewritten = response.json().get("response", "").strip()
                # æ¸…ç†å¯èƒ½çš„å‰ç¼€
                for prefix in ['æ”¹è¿›åçš„æŸ¥è¯¢å­—ç¬¦ä¸²', 'æŸ¥è¯¢', 'é‡å†™', 'ï¼š', ':', 'ä¼˜åŒ–åçš„']:
                    rewritten = rewritten.replace(prefix, '').strip()
                # å–ç¬¬ä¸€è¡Œ
                rewritten = rewritten.split('\n')[0].strip()

                # éªŒè¯ï¼šé‡å†™åçš„æŸ¥è¯¢å¿…é¡»åŒ…å«åŸæŸ¥è¯¢çš„å…³é”®è¯
                original_words = set(query.lower().split())
                rewritten_words = set(rewritten.lower().split())

                # å¦‚æœåŸæŸ¥è¯¢çš„è¯éƒ½ä¸åœ¨é‡å†™ä¸­ï¼Œè¯´æ˜é‡å†™å¤±è´¥
                if original_words and not original_words & rewritten_words:
                    if self.enable_fallback:
                        print(f"âš ï¸  é‡å†™åç¦»åŸæ„ï¼Œä¿ç•™åŸæŸ¥è¯¢")
                    return query

                return rewritten if rewritten else query
        except Exception as e:
            print(f"âš ï¸  LLM é‡å†™å¤±è´¥: {e}")

        return query

    def _hyde(self, query: str) -> str:
        """
        HyDE (Hypothetical Document Embeddings)

        åŸç†ï¼š
        1. è®© LLM ç”Ÿæˆä¸€ä¸ªå‡è®¾çš„ç­”æ¡ˆ
        2. ç”¨å‡è®¾çš„ç­”æ¡ˆå»æ£€ç´¢ï¼ˆè€Œä¸æ˜¯åŸå§‹æŸ¥è¯¢ï¼‰
        3. å‡è®¾ç­”æ¡ˆé€šå¸¸åŒ…å«æ›´ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯

        é€‚ç”¨åœºæ™¯ï¼š
        - è¯­ä¹‰æŸ¥è¯¢ï¼ˆ"æ€ä¹ˆ..." "ä¸ºä»€ä¹ˆ..."ï¼‰
        - æ¦‚å¿µæ€§æŸ¥è¯¢
        """
        prompt = f"""è¯·ä¸ºä»¥ä¸‹é—®é¢˜ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„å‡è®¾æ€§ç­”æ¡ˆï¼ˆ50-100å­—ï¼‰ã€‚

é—®é¢˜ï¼š{query}

è¦æ±‚ï¼š
1. åŸºäºå¸¸è¯†ç”Ÿæˆä¸€ä¸ªåˆç†çš„ç­”æ¡ˆ
2. ç­”æ¡ˆåº”è¯¥åŒ…å«ç›¸å…³çš„å…³é”®æ¦‚å¿µå’Œæœ¯è¯­
3. ä¸éœ€è¦å‡†ç¡®ï¼Œä½†è¦æœ‰ä»£è¡¨æ€§
4. ä½¿ç”¨æ¸…æ™°çš„æ®µè½æ ¼å¼

å‡è®¾æ€§ç­”æ¡ˆï¼š"""

        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.5, "num_predict": 200}
                },
                timeout=60
            )

            if response.status_code == 200:
                hypothetical_answer = response.json().get("response", "").strip()
                # æ¸…ç†å¤šä½™çš„å‰ç¼€
                hypothetical_answer = re.sub(r'^(å‡è®¾æ€§ç­”æ¡ˆ|ç­”æ¡ˆ|ï¼š|:)\s*', '', hypothetical_answer)
                return hypothetical_answer if hypothetical_answer else query
        except Exception as e:
            print(f"âš ï¸  HyDE ç”Ÿæˆå¤±è´¥: {e}")

        return query

    def _step_back(self, query: str) -> str:
        """
        Step-back Prompting

        åŸç†ï¼š
        1. å°†å…·ä½“é—®é¢˜æŠ½è±¡æˆæ›´é«˜å±‚æ¬¡çš„æ¦‚å¿µæ€§é—®é¢˜
        2. å…ˆå›ç­”é«˜å±‚æ¬¡é—®é¢˜ï¼Œå†å›åˆ°å…·ä½“é—®é¢˜
        3. é€‚åˆå¤æ‚ã€ä¸“ä¸šçš„é—®é¢˜

        ç¤ºä¾‹ï¼š
        - "è¯¸è‘›äº®ç”¨ä»€ä¹ˆæ­¦å™¨ï¼Ÿ" â†’ "ä¸‰å›½æ—¶æœŸçš„å†›äº‹è£…å¤‡å’Œæ­¦å™¨"
        - "Python å¦‚ä½•å¤„ç†å¼‚å¸¸ï¼Ÿ" â†’ "ç¼–ç¨‹è¯­è¨€ä¸­çš„å¼‚å¸¸å¤„ç†æœºåˆ¶"
        """
        prompt = f"""è¯·å°†ä»¥ä¸‹å…·ä½“é—®é¢˜æŠ½è±¡æˆä¸€ä¸ªæ›´é«˜å±‚æ¬¡çš„æ¦‚å¿µæ€§é—®é¢˜ã€‚

åŸé—®é¢˜ï¼š{query}

è¦æ±‚ï¼š
1. æå–é—®é¢˜èƒŒåçš„æ ¸å¿ƒæ¦‚å¿µ
2. å°†å…·ä½“é—®é¢˜æŠ½è±¡æˆé€šç”¨åŸç†
3. ä¿æŒé—®é¢˜ç®€æ´ï¼Œ10-20 å­—
4. åªè¾“å‡ºæŠ½è±¡åçš„é—®é¢˜ï¼Œä¸è¦å…¶ä»–å†…å®¹

æŠ½è±¡åçš„é—®é¢˜ï¼š"""

        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.3, "num_predict": 100}
                },
                timeout=60
            )

            if response.status_code == 200:
                abstract_query = response.json().get("response", "").strip()
                # æ¸…ç†å¤šä½™çš„å‰ç¼€
                abstract_query = re.sub(r'^(æŠ½è±¡åçš„é—®é¢˜|é—®é¢˜|ï¼š|:)\s*', '', abstract_query)
                # å–ç¬¬ä¸€è¡Œ
                abstract_query = abstract_query.split('\n')[0].strip()
                return abstract_query if abstract_query else query
        except Exception as e:
            print(f"âš ï¸  Step-back å¤±è´¥: {e}")

        return query

    def _evaluate_rewrite_quality(self, original_query: str, rewritten_query: str) -> float:
        """
        è¯„ä¼°é‡å†™è´¨é‡ï¼ˆæ‰“åˆ† 0-10ï¼‰

        è¯„ä¼°æ ‡å‡†ï¼š
        1. æ˜¯å¦ä¿ç•™äº†åŸæŸ¥è¯¢çš„å…³é”®ä¿¡æ¯
        2. æ˜¯å¦æ·»åŠ äº†æœ‰ç”¨çš„è¡¥å……ä¿¡æ¯
        3. æ˜¯å¦æ”¹å˜äº†åŸæ„
        4. æŸ¥è¯¢æ˜¯å¦ç®€æ´æ¸…æ™°
        """
        prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹æŸ¥è¯¢é‡å†™çš„è´¨é‡ï¼ˆ0-10åˆ†ï¼‰ã€‚

åŸæŸ¥è¯¢ï¼š{original_query}
é‡å†™åï¼š{rewritten_query}

è¯„åˆ†æ ‡å‡†ï¼š
1. ä¿ç•™äº†åŸæŸ¥è¯¢çš„æ‰€æœ‰å…³é”®è¯ï¼ˆ3åˆ†ï¼‰
2. æ·»åŠ äº†æœ‰ç”¨çš„è¡¥å……ä¿¡æ¯ï¼ˆ3åˆ†ï¼‰
3. æ²¡æœ‰æ”¹å˜åŸæ„ï¼ˆ2åˆ†ï¼‰
4. ç®€æ´æ¸…æ™°ï¼ˆ2åˆ†ï¼‰

è¦æ±‚ï¼š
- åªè¾“å‡ºä¸€ä¸ª 0-10 çš„æ•°å­—ï¼ˆå¯ä»¥æ˜¯å°æ•°ï¼‰
- å¦‚æœé‡å†™åæŸ¥è¯¢ä¸¢å¤±äº†åŸæŸ¥è¯¢çš„å…³é”®ä¿¡æ¯ï¼Œç»™ä½åˆ†ï¼ˆ<5åˆ†ï¼‰
- å¦‚æœé‡å†™ä¸åˆç†æˆ–åç¦»åŸæ„ï¼Œç»™ä½åˆ†ï¼ˆ<5åˆ†ï¼‰

è¯„åˆ†ï¼š"""

        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.1, "num_predict": 10}
                },
                timeout=30
            )

            if response.status_code == 200:
                score_text = response.json().get("response", "").strip()
                # æå–æ•°å­—
                score_match = re.search(r'(\d+\.?\d*)', score_text)
                if score_match:
                    score = float(score_match.group(1))
                    return min(score, 10.0)  # ç¡®ä¿ä¸è¶…è¿‡10
        except Exception as e:
            if self.enable_fallback:
                print(f"âš ï¸  è¯„åˆ†å¤±è´¥: {e}")

        return 6.0  # é»˜è®¤ä¸­ç­‰åˆ†æ•°

    def _is_simple_query(self, query: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºç®€å•æŸ¥è¯¢ï¼ˆä¸éœ€è¦é‡å†™ï¼‰

        ç®€å•æŸ¥è¯¢ç‰¹å¾ï¼š
        1. é•¿åº¦ <= 15å­—
        2. åŒ…å«æ˜ç¡®çš„å…³é”®è¯ï¼ˆåè¯ã€ä¸“æœ‰åè¯ï¼‰
        3. æ²¡æœ‰æ¨¡ç³Šè¡¨è¿°ï¼ˆ"é‚£ä¸ª"ã€"æ€ä¹ˆ"ã€"ä»€ä¹ˆ"ç­‰ï¼‰
        """
        # é•¿åº¦æ£€æŸ¥
        if len(query) <= 15:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¨¡ç³Šè¯
            vague_words = ["é‚£ä¸ª", "æ€ä¹ˆ", "å¦‚ä½•", "ä»€ä¹ˆ", "å“ªä¸ª", "å“ªäº›", "è¿˜æ˜¯", "æˆ–è€…"]
            if not any(vw in query for vw in vague_words):
                return True

        return False

    def rewrite(self, query: str, verbose: bool = True, compare_mode: bool = False) -> Dict:
        """
        é‡å†™æŸ¥è¯¢ï¼ˆå¸¦è´¨é‡æ£€æŸ¥å’Œå›é€€æœºåˆ¶ï¼‰

        Args:
            query: åŸå§‹æŸ¥è¯¢
            verbose: æ˜¯å¦æ˜¾ç¤ºé‡å†™ä¿¡æ¯
            compare_mode: æ˜¯å¦å¼€å¯å¯¹æ¯”æ¨¡å¼ï¼ˆåŒæ—¶ç”¨åŸæŸ¥è¯¢å’Œé‡å†™æŸ¥è¯¢æ£€ç´¢ï¼‰

        Returns:
            åŒ…å«é‡å†™ç»“æœå’Œè¯„åˆ†çš„å­—å…¸
        """
        result = {
            "original_query": query,
            "rewritten_query": query,
            "score": 0.0,
            "use_rewrite": False,
            "reason": ""
        }

        if verbose:
            print(f"\nğŸ“ åŸå§‹æŸ¥è¯¢: {query}")
            print(f"ğŸ”§ é‡å†™æ–¹æ³•: {self.method}")

        # æ™ºèƒ½è·³è¿‡ï¼šç®€å•æŸ¥è¯¢ä¸éœ€è¦é‡å†™
        if self._is_simple_query(query):
            if verbose:
                print("ğŸ’¡ æ£€æµ‹åˆ°ç®€å•æŸ¥è¯¢ï¼Œè·³è¿‡é‡å†™ï¼ˆç›´æ¥ä½¿ç”¨åŸæŸ¥è¯¢ï¼‰")
            result["reason"] = "ç®€å•æŸ¥è¯¢ï¼Œæ— éœ€é‡å†™"
            return result

        # æ‰§è¡Œé‡å†™
        if self.method == "llm_rewrite":
            rewritten = self._llm_rewrite(query)
            if verbose and rewritten != query:
                print(f"âœ¨ åˆæ­¥é‡å†™: {rewritten}")
            result["rewritten_query"] = rewritten

        elif self.method == "hyde":
            hypothetical = self._hyde(query)
            if verbose and hypothetical != query:
                print(f"ğŸ’­ å‡è®¾ç­”æ¡ˆ: {hypothetical[:100]}...")
            result["rewritten_query"] = hypothetical

        elif self.method == "step_back":
            abstract = self._step_back(query)
            if verbose and abstract != query:
                print(f"ğŸ” æŠ½è±¡é—®é¢˜: {abstract}")
            result["rewritten_query"] = abstract

        else:
            print(f"âš ï¸  æœªçŸ¥çš„é‡å†™æ–¹æ³•: {self.method}")
            result["reason"] = "æœªçŸ¥çš„é‡å†™æ–¹æ³•"
            return result

        # å¦‚æœæŸ¥è¯¢æ²¡æœ‰è¢«é‡å†™
        if result["rewritten_query"] == query:
            if verbose:
                print("â„¹ï¸  æŸ¥è¯¢æ— éœ€é‡å†™")
            result["reason"] = "æŸ¥è¯¢æ— éœ€é‡å†™"
            return result

        # è´¨é‡è¯„åˆ†
        if self.enable_fallback:
            score = self._evaluate_rewrite_quality(query, result["rewritten_query"])
            result["score"] = score

            if verbose:
                print(f"ğŸ“Š é‡å†™è´¨é‡è¯„åˆ†: {score}/10")

            # å›é€€æœºåˆ¶ï¼šå¦‚æœè¯„åˆ†ä½äºé˜ˆå€¼ï¼Œä½¿ç”¨åŸæŸ¥è¯¢
            # é˜ˆå€¼ä» 5.0 é™ä½åˆ° 3.0ï¼Œæ›´å®¹æ˜“æ¥å—é‡å†™ç»“æœ
            if score < 3.0:
                if verbose:
                    print(f"âš ï¸  é‡å†™è´¨é‡å¤ªä½ï¼ˆ< 3åˆ†ï¼‰ï¼Œä½¿ç”¨åŸæŸ¥è¯¢")
                result["rewritten_query"] = query
                result["use_rewrite"] = False
                result["reason"] = f"é‡å†™è´¨é‡å¤ªä½ï¼ˆ{score:.1f}åˆ†ï¼‰ï¼Œå›é€€åˆ°åŸæŸ¥è¯¢"
            else:
                if verbose:
                    if score >= 7.0:
                        print(f"âœ… é‡å†™è´¨é‡ä¼˜ç§€ï¼Œä½¿ç”¨ä¼˜åŒ–åçš„æŸ¥è¯¢")
                    else:
                        print(f"âœ… é‡å†™è´¨é‡å¯æ¥å—ï¼ˆ{score:.1f}åˆ†ï¼‰ï¼Œå°è¯•ä½¿ç”¨")
                result["use_rewrite"] = True
                result["reason"] = f"é‡å†™è´¨é‡è¯„åˆ† {score:.1f}åˆ†"
        else:
            # ä¸å¯ç”¨å›é€€æœºåˆ¶ï¼Œç›´æ¥ä½¿ç”¨é‡å†™ç»“æœ
            result["use_rewrite"] = True
            result["reason"] = "å·²ç¦ç”¨å›é€€æœºåˆ¶"

        return result

# ============================================================================
# å¤ç”¨åŸæœ‰çš„ç±»ï¼ˆç®€åŒ–ï¼‰
# ============================================================================

class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å™¨"""
    @staticmethod
    def load_txt(file_path: str) -> str:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()

    @staticmethod
    def load_directory(directory: str) -> List[Tuple[str, str]]:
        documents = []
        path = Path(directory)
        for file_path in path.rglob('*.txt'):
            try:
                content = DocumentLoader.load_txt(str(file_path))
                if content.strip():
                    documents.append((file_path.name, content))
                    print(f"âœ… å·²åŠ è½½: {file_path.name}")
            except Exception as e:
                print(f"âŒ åŠ è½½å¤±è´¥ {file_path.name}: {e}")
        return documents

class TextSplitter:
    """æ–‡æœ¬åˆ†å‰²å™¨"""
    def __init__(self, chunk_size: int = CHUNK_SIZE, chunk_overlap: int = CHUNK_OVERLAP):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap

    def split_text(self, text: str, metadata: str = "") -> List[Dict]:
        chunks = []
        text = re.sub(r'\n+', '\n', text).strip()
        paragraphs = text.split('\n\n')

        current_chunk = ""
        chunk_id = 0

        for para in paragraphs:
            para = para.strip()
            if not para:
                continue

            if len(current_chunk) + len(para) + 2 <= self.chunk_size:
                current_chunk += para + "\n\n"
            else:
                if current_chunk.strip():
                    chunks.append({
                        "content": current_chunk.strip(),
                        "metadata": metadata,
                        "chunk_id": chunk_id
                    })
                    chunk_id += 1

                if self.chunk_overlap > 0 and current_chunk:
                    overlap_text = current_chunk[-self.chunk_overlap:]
                    current_chunk = overlap_text + para + "\n\n"
                else:
                    current_chunk = para + "\n\n"

        if current_chunk.strip():
            chunks.append({
                "content": current_chunk.strip(),
                "metadata": metadata,
                "chunk_id": chunk_id
            })

        return chunks

    def split_documents(self, documents: List[Tuple[str, str]]) -> List[Dict]:
        all_chunks = []
        for filename, content in documents:
            chunks = self.split_text(content, metadata=filename)
            all_chunks.extend(chunks)
        return all_chunks

class OllamaEmbedding:
    """Ollama Embedding ç”Ÿæˆå™¨"""
    def __init__(self):
        self.base_url = OLLAMA_BASE_URL
        self.model = EMBEDDING_MODEL
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code != 200:
                raise Exception("Ollama æœªè¿è¡Œ")
            print(f"âœ… Ollama è¿æ¥æˆåŠŸ")
        except Exception as e:
            raise Exception(f"æ— æ³•è¿æ¥åˆ° Ollama: {e}")

    def get_embedding(self, text: str) -> List[float]:
        try:
            response = requests.post(
                f"{self.base_url}/api/embeddings",
                json={"model": self.model, "prompt": text},
                timeout=60
            )
            if response.status_code == 200:
                return response.json().get("embedding", [])
            return []
        except:
            return []

    def get_embeddings_batch(self, texts: List[str], batch_size: int = 10) -> List[List[float]]:
        """æ‰¹é‡è·å– Embedding"""
        embeddings = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            for text in batch:
                emb = self.get_embedding(text)
                if emb:
                    embeddings.append(emb)
                    print(f"âœ… [{len(embeddings)}/{len(texts)}] ç”Ÿæˆ embedding")
                else:
                    embeddings.append([0.0] * 768)
        return embeddings

class FaissIndex:
    """Faiss å‘é‡ç´¢å¼•"""
    def __init__(self, dimension: int = 768):
        self.dimension = dimension
        self.index = None
        self.chunks = []
        self.embeddings = None

    def build_index(self, chunks: List[Dict], embeddings: List[List[float]]):
        self.chunks = chunks
        self.embeddings = np.array(embeddings, dtype='float32')

        if self.embeddings.shape[1] != self.dimension:
            self.dimension = self.embeddings.shape[1]

        self.index = faiss.IndexFlatL2(self.dimension)
        self.index.add(self.embeddings)

        print(f"âœ… Faiss ç´¢å¼•æ„å»ºå®Œæˆ: {len(chunks)} ä¸ªæ–‡æ¡£å—")

    def save(self):
        """ä¿å­˜ç´¢å¼•"""
        faiss.write_index(self.index, f"{INDEX_PREFIX}_faiss.bin")
        with open(f"{INDEX_PREFIX}_chunks.pkl", 'wb') as f:
            pickle.dump({
                'chunks': self.chunks,
                'embeddings': self.embeddings
            }, f)
        print(f"âœ… ç´¢å¼•å·²ä¿å­˜: {INDEX_PREFIX}_*.bin")

    def load(self):
        """åŠ è½½ç´¢å¼•"""
        self.index = faiss.read_index(f"{INDEX_PREFIX}_faiss.bin")
        with open(f"{INDEX_PREFIX}_chunks.pkl", 'rb') as f:
            data = pickle.load(f)
            self.chunks = data['chunks']
            self.embeddings = data['embeddings']
        self.dimension = self.index.d
        print(f"âœ… ç´¢å¼•å·²åŠ è½½: {len(self.chunks)} ä¸ªæ–‡æ¡£å—")

    def search(self, query_embedding: List[float], top_k: int = COARSE_TOP_K) -> List[Dict]:
        """æœç´¢æ–‡æ¡£"""
        query_array = np.array([query_embedding], dtype='float32')
        distances, indices = self.index.search(query_array, top_k)

        results = []
        for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):
            if idx < len(self.chunks):
                chunk = self.chunks[idx].copy()
                chunk['score'] = float(dist)
                results.append(chunk)

        return results

class OllamaChat:
    """Ollama é—®ç­”ç”Ÿæˆå™¨"""
    def __init__(self):
        self.base_url = OLLAMA_BASE_URL
        self.model = CHAT_MODEL

    def generate_answer(self, question: str, context: str) -> str:
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®ç­”åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

å‚è€ƒæ–‡æ¡£ï¼š
{context}

é—®é¢˜ï¼š{question}

è¦æ±‚ï¼š
1. ç­”æ¡ˆå¿…é¡»åŸºäºå‚è€ƒæ–‡æ¡£ä¸­çš„ä¿¡æ¯
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜"æä¾›çš„æ–‡æ¡£ä¸­æ²¡æœ‰åŒ…å«è¯¥é—®é¢˜çš„ç­”æ¡ˆ"
3. ä¿æŒç­”æ¡ˆç®€æ´å‡†ç¡®

ç­”æ¡ˆï¼š"""

        try:
            response = requests.post(
                f"{self.base_url}/api/generate",
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {"temperature": 0.3, "num_predict": 1000}
                },
                timeout=120
            )

            if response.status_code == 200:
                return response.json().get("response", "âš ï¸  æ— æ³•ç”Ÿæˆç­”æ¡ˆ")
            return f"âš ï¸  ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {response.status_code}"
        except Exception as e:
            return f"âš ï¸  ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {e}"

# ============================================================================
# å¸¦ Query Rewrite çš„ RAG ç³»ç»Ÿ
# ============================================================================

class RAGSystemWithQueryRewrite:
    """å¸¦æŸ¥è¯¢é‡å†™çš„ RAG ç³»ç»Ÿ"""

    def __init__(self, rewrite_method: str = "llm_rewrite", enable_fallback: bool = True,
                 compare_mode: bool = False):
        """
        Args:
            rewrite_method: é‡å†™æ–¹æ³•
                - "llm_rewrite": LLM æŸ¥è¯¢é‡å†™ï¼ˆæ¨èï¼Œä¿å®ˆç­–ç•¥ï¼‰
                - "hyde": HyDE
                - "step_back": Step-back
            enable_fallback: æ˜¯å¦å¯ç”¨å›é€€æœºåˆ¶ï¼ˆé»˜è®¤Trueï¼‰
            compare_mode: å¯¹æ¯”æ¨¡å¼ï¼ˆåŒæ—¶ç”¨åŸæŸ¥è¯¢å’Œé‡å†™æŸ¥è¯¢æ£€ç´¢ï¼‰
        """
        self.embedder = OllamaEmbedding()
        self.chat = OllamaChat()
        self.index = FaissIndex()
        self.rewriter = QueryRewriter(method=rewrite_method, enable_fallback=enable_fallback)
        self.rewrite_method = rewrite_method
        self.compare_mode = compare_mode

    def build_knowledge_base(self):
        """æ„å»ºçŸ¥è¯†åº“"""
        print("\n" + "=" * 80)
        print("ğŸ“š çŸ¥è¯†åº“æ„å»º")
        print("=" * 80)

        # åŠ è½½æ–‡æ¡£
        print("\nç¬¬ä¸€æ­¥ï¼šåŠ è½½æ–‡æ¡£")
        loader = DocumentLoader()
        documents = loader.load_directory(DOCS_DIR)

        if not documents:
            print(f"âŒ æœªæ‰¾åˆ°æ–‡æ¡£ï¼Œè¯·åœ¨ {DOCS_DIR}/ ç›®å½•ä¸­æ”¾å…¥æ–‡æ¡£")
            return

        print(f"\nâœ… å…±åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")

        # åˆ†å‰²æ–‡æœ¬
        print("\nç¬¬äºŒæ­¥ï¼šåˆ†å‰²æ–‡æœ¬")
        splitter = TextSplitter()
        chunks = splitter.split_documents(documents)
        print(f"âœ… å…±åˆ†å‰²æˆ {len(chunks)} ä¸ªæ–‡æœ¬å—")

        # ç”Ÿæˆ embedding
        print("\nç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆ Embedding")
        texts = [chunk['content'] for chunk in chunks]
        embeddings = self.embedder.get_embeddings_batch(texts)

        # æ„å»ºç´¢å¼•
        print("\nç¬¬å››æ­¥ï¼šæ„å»º Faiss ç´¢å¼•")
        self.index.build_index(chunks, embeddings)

        # ä¿å­˜
        print("\nç¬¬äº”æ­¥ï¼šä¿å­˜ç´¢å¼•")
        self.index.save()
        print("\nâœ¨ çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")

    def load_knowledge_base(self):
        """åŠ è½½çŸ¥è¯†åº“"""
        self.index.load()
        print("âœ… çŸ¥è¯†åº“å·²åŠ è½½")

    def query(self, question: str) -> Dict:
        """æŸ¥è¯¢ï¼ˆå¸¦å¯¹æ¯”æ¨¡å¼ï¼‰"""
        print(f"\n{'=' * 80}")
        print(f"ğŸ” æŸ¥è¯¢: {question}")
        print(f"{'=' * 80}")

        # ========== æŸ¥è¯¢é‡å†™ ==========
        print(f"\nğŸ”§ ç¬¬ä¸€æ­¥ï¼šæŸ¥è¯¢é‡å†™")
        rewrite_result = self.rewriter.rewrite(question, verbose=True)

        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å¯¹æ¯”æ¨¡å¼
        if self.compare_mode and rewrite_result["use_rewrite"]:
            print(f"\nğŸ”„ å¯¹æ¯”æ¨¡å¼ï¼šåŒæ—¶ç”¨åŸæŸ¥è¯¢å’Œé‡å†™æŸ¥è¯¢æ£€ç´¢")

            # ç”¨åŸæŸ¥è¯¢æ£€ç´¢
            original_embedding = self.embedder.get_embedding(question)
            if not original_embedding:
                return {"error": "æ— æ³•ç”ŸæˆæŸ¥è¯¢å‘é‡"}

            original_results = self.index.search(original_embedding, top_k=COARSE_TOP_K)

            # ç”¨é‡å†™æŸ¥è¯¢æ£€ç´¢
            rewritten_embedding = self.embedder.get_embedding(rewrite_result["rewritten_query"])
            if not rewritten_embedding:
                return {"error": "æ— æ³•ç”ŸæˆæŸ¥è¯¢å‘é‡"}

            rewritten_results = self.index.search(rewritten_embedding, top_k=COARSE_TOP_K)

            # å¯¹æ¯”ç»“æœ
            print(f"\nğŸ“Š ç¬¬äºŒæ­¥ï¼šå¯¹æ¯”æ£€ç´¢ç»“æœ")
            print(f"\nåŸæŸ¥è¯¢ Top-3:")
            for i, r in enumerate(original_results[:3]):
                print(f"  [{i+1}] {r['metadata'][:40]:40s} (åˆ†æ•°: {r['score']:.4f})")

            print(f"\né‡å†™æŸ¥è¯¢ Top-3:")
            for i, r in enumerate(rewritten_results[:3]):
                print(f"  [{i+1}] {r['metadata'][:40]:40s} (åˆ†æ•°: {r['score']:.4f})")

            # ä½¿ç”¨é‡å†™æŸ¥è¯¢çš„ç»“æœ
            final_results = rewritten_results[:FINAL_TOP_K]

        else:
            # ä½¿ç”¨é‡å†™æŸ¥è¯¢ï¼ˆæˆ–åŸæŸ¥è¯¢ï¼Œå¦‚æœå›é€€äº†ï¼‰
            query_to_use = rewrite_result["rewritten_query"]
            print(f"\nğŸ“Š ç¬¬äºŒæ­¥ï¼šå‘é‡æ£€ç´¢ï¼ˆå¬å› top-{COARSE_TOP_K}ï¼‰")

            query_embedding = self.embedder.get_embedding(query_to_use)
            if not query_embedding:
                return {"error": "æ— æ³•ç”ŸæˆæŸ¥è¯¢å‘é‡"}

            results = self.index.search(query_embedding, top_k=COARSE_TOP_K)
            print(f"âœ… æ£€ç´¢å®Œæˆ")

            # æœ€ç»ˆç»“æœ
            final_results = results[:FINAL_TOP_K]

        # ç»„è£…ä¸Šä¸‹æ–‡
        context = "\n\n".join([
            f"ã€æ¥æº: {r['metadata'][:50]}ã€‘\n{r['content'][:300]}..."
            for r in final_results
        ])

        # ç”Ÿæˆç­”æ¡ˆ
        print(f"\nğŸ’­ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
        answer = self.chat.generate_answer(question, context)

        return {
            "answer": answer,
            "sources": final_results,
            "query": question,
            "rewritten_query": rewrite_result["rewritten_query"],
            "rewrite_score": rewrite_result.get("score", 0.0),
            "use_rewrite": rewrite_result["use_rewrite"],
            "rewrite_reason": rewrite_result["reason"]
        }

# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

def main():
    print("=" * 80)
    print("ğŸ¤– Ollama + Faiss + Query Rewrite æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ç³»ç»Ÿ")
    print("=" * 80)
    print("\nğŸ“š æ¼”ç¤ºæŸ¥è¯¢é‡å†™ï¼ˆQuery Rewritingï¼‰çš„æ•ˆæœ")

    # æ£€æŸ¥ Ollama
    try:
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        if response.status_code != 200:
            print("\nâŒ Ollama æœªè¿è¡Œ")
            return
    except:
        print("\nâŒ æ— æ³•è¿æ¥ Ollama")
        return

    # é€‰æ‹©é‡å†™æ–¹æ³•
    print("\né€‰æ‹©æŸ¥è¯¢é‡å†™æ–¹æ³•:")
    print("1. LLM æŸ¥è¯¢é‡å†™ï¼ˆæ¨èï¼Œä¿å®ˆç­–ç•¥ï¼‰â­")
    print("2. HyDE - ç”Ÿæˆå‡è®¾ç­”æ¡ˆï¼ˆé€‚åˆè¯­ä¹‰æŸ¥è¯¢ï¼‰")
    print("3. Step-back - æŠ½è±¡åŒ–é—®é¢˜ï¼ˆé€‚åˆå¤æ‚é—®é¢˜ï¼‰")
    print("4. ä¸ä½¿ç”¨é‡å†™ï¼ˆå¯¹æ¯”åŸºçº¿ï¼‰")
    print("\nè¾“å…¥ 1-4ï¼ˆé»˜è®¤ 1ï¼‰: ", end="")

    try:
        choice = input().strip()
        if choice == "2":
            rewrite_method = "hyde"
            print("\nâœ… ä½¿ç”¨ HyDE æ–¹æ³•")
        elif choice == "3":
            rewrite_method = "step_back"
            print("\nâœ… ä½¿ç”¨ Step-back æ–¹æ³•")
        elif choice == "4":
            rewrite_method = None
            print("\nâœ… ä¸ä½¿ç”¨æŸ¥è¯¢é‡å†™")
        else:
            rewrite_method = "llm_rewrite"
            print("\nâœ… ä½¿ç”¨ LLM æŸ¥è¯¢é‡å†™ï¼ˆé»˜è®¤ï¼‰")
    except:
        rewrite_method = "llm_rewrite"
        print("\nâœ… ä½¿ç”¨ LLM æŸ¥è¯¢é‡å†™ï¼ˆé»˜è®¤ï¼‰")

    # æ˜¯å¦å¯ç”¨å›é€€æœºåˆ¶
    enable_fallback = True
    if rewrite_method:
        print("\næ˜¯å¦å¯ç”¨å›é€€æœºåˆ¶ï¼Ÿï¼ˆé‡å†™è´¨é‡ä½æ—¶è‡ªåŠ¨ä½¿ç”¨åŸæŸ¥è¯¢ï¼‰")
        print("1. å¯ç”¨å›é€€æœºåˆ¶ï¼ˆæ¨èï¼‰â­")
        print("2. ç¦ç”¨å›é€€æœºåˆ¶")
        print("\nè¾“å…¥ 1-2ï¼ˆé»˜è®¤ 1ï¼‰: ", end="")

        try:
            choice = input().strip()
            enable_fallback = (choice != "2")
            if enable_fallback:
                print("\nâœ… å·²å¯ç”¨å›é€€æœºåˆ¶")
            else:
                print("\nâš ï¸  å·²ç¦ç”¨å›é€€æœºåˆ¶ï¼ˆå¯èƒ½ä¼šå‡ºç°é‡å†™å¤±è´¥çš„æƒ…å†µï¼‰")
        except:
            enable_fallback = True
            print("\nâœ… å·²å¯ç”¨å›é€€æœºåˆ¶ï¼ˆé»˜è®¤ï¼‰")

    # æ˜¯å¦å¼€å¯å¯¹æ¯”æ¨¡å¼
    compare_mode = False
    if rewrite_method and enable_fallback:
        print("\næ˜¯å¦å¼€å¯å¯¹æ¯”æ¨¡å¼ï¼Ÿï¼ˆåŒæ—¶ç”¨åŸæŸ¥è¯¢å’Œé‡å†™æŸ¥è¯¢æ£€ç´¢ï¼‰")
        print("1. ä¸å¼€å¯å¯¹æ¯”æ¨¡å¼ï¼ˆé»˜è®¤ï¼Œæ›´å¿«ï¼‰")
        print("2. å¼€å¯å¯¹æ¯”æ¨¡å¼ï¼ˆå¯ä»¥çœ‹åˆ°å¯¹æ¯”æ•ˆæœï¼‰â­")
        print("\nè¾“å…¥ 1-2ï¼ˆé»˜è®¤ 1ï¼‰: ", end="")

        try:
            choice = input().strip()
            compare_mode = (choice == "2")
            if compare_mode:
                print("\nâœ… å·²å¼€å¯å¯¹æ¯”æ¨¡å¼")
            else:
                print("\nâœ… æœªå¼€å¯å¯¹æ¯”æ¨¡å¼")
        except:
            compare_mode = False
            print("\nâœ… æœªå¼€å¯å¯¹æ¯”æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰")

    # åˆ›å»ºç³»ç»Ÿ
    try:
        if rewrite_method:
            rag = RAGSystemWithQueryRewrite(
                rewrite_method=rewrite_method,
                enable_fallback=enable_fallback,
                compare_mode=compare_mode
            )
        else:
            # ä¸ä½¿ç”¨é‡å†™ï¼Œä½¿ç”¨åŸºç¡€ç³»ç»Ÿ
            rag = RAGSystemWithQueryRewrite(
                rewrite_method="llm_rewrite",
                enable_fallback=False
            )
            # ç¦ç”¨é‡å†™å™¨
            rag.rewrite_method = None
    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        print("\nğŸ’¡ è¯·ç¡®ä¿å·²ä¸‹è½½ embedding æ¨¡å‹: ollama pull nomic-embed-text")
        return

    # åˆ›å»ºæ–‡æ¡£ç›®å½•
    Path(DOCS_DIR).mkdir(exist_ok=True)

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ–‡æ¡£
    if not list(Path(DOCS_DIR).rglob('*.txt')):
        print(f"\nğŸ“ åœ¨ {DOCS_DIR}/ ç›®å½•ä¸­æ·»åŠ ä½ çš„æ–‡æ¡£ï¼ˆ.txt æ–‡ä»¶ï¼‰")
        print("ç„¶åé‡æ–°è¿è¡Œç¨‹åº")
        return

    # æ„å»ºæˆ–åŠ è½½çŸ¥è¯†åº“
    if Path(f"{INDEX_PREFIX}_faiss.bin").exists():
        print(f"\næ£€æµ‹åˆ°å·²æœ‰ç´¢å¼•ï¼Œæ˜¯å¦é‡æ–°æ„å»ºï¼Ÿ(y/n): ", end="")
        try:
            choice = input().strip().lower()
            if choice == 'y':
                rag.build_knowledge_base()
            else:
                rag.load_knowledge_base()
        except:
            rag.load_knowledge_base()
    else:
        rag.build_knowledge_base()

    # äº¤äº’å¼é—®ç­”
    print("\n" + "=" * 80)
    print("ğŸ’¬ å¼€å§‹é—®ç­”ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰")
    print("=" * 80)

    # æç¤ºç¤ºä¾‹é—®é¢˜ï¼ˆé‡ç‚¹å±•ç¤ºæŸ¥è¯¢é‡å†™çš„æ•ˆæœï¼‰
    print("\nğŸ’¡ ç¤ºä¾‹é—®é¢˜ï¼ˆè§‚å¯ŸæŸ¥è¯¢é‡å†™çš„æ•ˆæœï¼‰:")
    print("  - é‚£ä¸ªéª‘ç€èµ¤å…”é©¬çš„äººæ˜¯è°ï¼Ÿ  (LLMé‡å†™ â†’ å•å¸ƒ èµ¤å…”é©¬ ä¸‰å›½)")
    print("  - æ€ä¹ˆåšçº¢çƒ§è‚‰ï¼Ÿ             (HyDE â†’ ç”Ÿæˆå‡è®¾ç­”æ¡ˆ)")
    print("  - Pythoné‡Œå¤„ç†é”™è¯¯           (LLMé‡å†™ â†’ Pythonå¼‚å¸¸å¤„ç†)")
    print("  - è¯¸è‘›äº®çš„æ‰‡å­               (LLMé‡å†™ â†’ è¯¸è‘›äº® é¹…æ¯›æ‰‡)")

    while True:
        print("\n" + "â”€" * 80)
        try:
            question = input("â“ ä½ çš„é—®é¢˜: ").strip()

            if not question:
                continue

            if question.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ å†è§ï¼")
                break

            # å¦‚æœç¦ç”¨äº†é‡å†™ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æŸ¥è¯¢
            if rag.rewrite_method is None:
                result = rag.query(question)
                # è¦†ç›–æ˜¾ç¤ºï¼Œå‡è£…æ²¡æœ‰é‡å†™
                result['rewritten_query'] = question
            else:
                result = rag.query(question)

            if "error" in result:
                print(f"\nâŒ {result['error']}")
                continue

            print("\n" + "â”€" * 80)
            print("ğŸ“– ç­”æ¡ˆ:")
            print("â”€" * 80)
            print(result['answer'])
            print("â”€" * 80)

            # æ˜¾ç¤ºé‡å†™ä¿¡æ¯
            if result.get('rewritten_query') and result['rewritten_query'] != result['query']:
                print(f"\nğŸ’¡ æŸ¥è¯¢é‡å†™ä¿¡æ¯:")
                print(f"   åŸå§‹æŸ¥è¯¢: {result['query']}")
                print(f"   é‡å†™æŸ¥è¯¢: {result['rewritten_query']}")
                if result.get('rewrite_score') > 0:
                    print(f"   è´¨é‡è¯„åˆ†: {result['rewrite_score']}/10")
                print(f"   æ˜¯å¦ä½¿ç”¨: {'æ˜¯' if result.get('use_rewrite') else 'å¦ï¼ˆå›é€€åˆ°åŸæŸ¥è¯¢ï¼‰'}")
                print(f"   åŸå› : {result.get('rewrite_reason', '')}")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ å‡ºé”™äº†: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()
