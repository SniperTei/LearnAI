RAFT高级RAG技术
==============

RAFT是Retrieval-Augmented Fine Tuning的缩写，是RAG的一种高级技术。

RAFT的核心思想：
通过特殊的微调方式，让模型学会在检索结果中识别真正有用的信息，忽略干扰文档。

RAFT与传统RAG的区别：
传统RAG直接使用检索到的文档，容易被不相关的文档误导。
RAFT通过混合相关文档和干扰文档进行训练，提升模型的抗干扰能力。

RAFT的训练方法：
1. 准备训练数据
   - 每个样本包含：问题 + 相关文档 + 干扰文档
   - 使用Oracle模型（如GPT-4）基于相关文档生成标准答案

2. 微调模型
   - 训练模型识别和使用相关文档
   - 要求答案包含引用

3. 评估指标
   - 引用准确率：是否引用了正确的文档
   - 干扰文档排除率：是否成功忽略干扰文档

RAFT的优势：
- 抗干扰能力强
- 引用准确性高
- 对检索质量要求相对较低

RAFT的局限性：
- 需要微调，成本高
- 需要准备训练数据
- 维护复杂度高

RAFT的应用场景：
- 检索质量较差的场景
- 需要精确引用的领域（医学、法律）
- 有专门团队维护的垂直应用

RAFT与LoRA：
RAFT通常与LoRA结合使用，降低微调成本。LoRA是一种参数高效的微调技术，只训练1-2%的参数。
