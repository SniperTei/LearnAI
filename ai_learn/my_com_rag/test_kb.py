#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ - ç”¨äºå¿«é€Ÿæµ‹è¯•çŸ¥è¯†åº“åŠŸèƒ½
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from backend.core.document_processor import DocumentProcessor
from backend.core.vector_store import VectorStoreManager
from backend.core.rag_chain import KnowledgeBase


def test_document_processing():
    """æµ‹è¯•æ–‡æ¡£å¤„ç†"""
    print("=" * 60)
    print("ğŸ“„ æµ‹è¯•æ–‡æ¡£å¤„ç†")
    print("=" * 60)

    processor = DocumentProcessor()

    # æµ‹è¯•åŠ è½½ç›®å½•ä¸­çš„æ–‡æ¡£
    documents_path = "data/documents"
    if Path(documents_path).exists():
        print(f"\nğŸ“‚ åŠ è½½ç›®å½•: {documents_path}")
        documents = processor.load_documents_from_directory(documents_path)
        print(f"âœ… åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")

        if documents:
            print(f"\nğŸ“ ç¬¬ä¸€ä¸ªæ–‡æ¡£é¢„è§ˆ:")
            print(f"å†…å®¹: {documents[0].page_content[:200]}...")
            print(f"å…ƒæ•°æ®: {documents[0].metadata}")
    else:
        print(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨: {documents_path}")
        print(f"è¯·åœ¨ {documents_path} ä¸­æ”¾å…¥ä¸€äº›æ–‡æ¡£è¿›è¡Œæµ‹è¯•")

    print()


def test_vector_store():
    """æµ‹è¯•å‘é‡æ•°æ®åº“"""
    print("=" * 60)
    print("ğŸ—„ï¸  æµ‹è¯•å‘é‡æ•°æ®åº“")
    print("=" * 60)

    manager = VectorStoreManager()
    info = manager.get_collection_info()

    print(f"\nğŸ“Š å‘é‡æ•°æ®åº“ä¿¡æ¯:")
    print(f"ç±»å‹: {info.get('type')}")
    print(f"é›†åˆåç§°: {info.get('collection_name')}")
    print(f"åˆå§‹åŒ–çŠ¶æ€: {info.get('initialized')}")

    if 'count' in info:
        print(f"æ–‡æ¡£æ•°é‡: {info.get('count')}")

    print()


def test_knowledge_base():
    """æµ‹è¯•çŸ¥è¯†åº“"""
    print("=" * 60)
    print("ğŸ¤– æµ‹è¯•çŸ¥è¯†åº“é—®ç­”")
    print("=" * 60)

    kb = KnowledgeBase()

    # è·å–çŸ¥è¯†åº“ä¿¡æ¯
    info = kb.get_info()
    print(f"\nğŸ“Š çŸ¥è¯†åº“çŠ¶æ€:")
    for key, value in info.items():
        print(f"  {key}: {value}")

    # æµ‹è¯•æœç´¢
    test_query = "äººå·¥æ™ºèƒ½"
    print(f"\nğŸ” æµ‹è¯•æœç´¢: '{test_query}'")

    try:
        results = kb.search(test_query, k=3)
        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")

        for i, result in enumerate(results, 1):
            print(f"\n  [{i}] ç›¸ä¼¼åº¦: {result.get('score', 'N/A')}")
            print(f"  å†…å®¹: {result.get('content', '')[:150]}...")
            if result.get('metadata'):
                print(f"  æ¥æº: {result['metadata'].get('file_name', 'N/A')}")
    except Exception as e:
        print(f"âš ï¸  æœç´¢å¤±è´¥: {e}")

    print()


def test_api_imports():
    """æµ‹è¯•APIå¯¼å…¥"""
    print("=" * 60)
    print("ğŸ”Œ æµ‹è¯•APIæ¨¡å—")
    print("=" * 60)

    try:
        from backend.api.main import app
        print("âœ… FastAPIåº”ç”¨å¯¼å…¥æˆåŠŸ")

        routes = []
        for route in app.routes:
            if hasattr(route, 'path') and hasattr(route, 'methods'):
                for method in route.methods:
                    routes.append(f"{method} {route.path}")

        print(f"\nğŸ“‹ å¯ç”¨çš„APIç«¯ç‚¹ ({len(routes)}):")
        for route in sorted(routes):
            print(f"  {route}")

    except Exception as e:
        print(f"âŒ APIå¯¼å…¥å¤±è´¥: {e}")

    print()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n")
    print("ğŸ§ª ä¼ä¸šçŸ¥è¯†åº“ - æµ‹è¯•è„šæœ¬")
    print("=" * 60)
    print()

    try:
        # æµ‹è¯•å„ä¸ªæ¨¡å—
        test_api_imports()
        test_document_processing()
        test_vector_store()
        test_knowledge_base()

        print("=" * 60)
        print("âœ… æµ‹è¯•å®Œæˆ!")
        print("=" * 60)
        print("\nğŸ’¡ æç¤º:")
        print("  1. åœ¨ data/documents/ ç›®å½•ä¸­æ”¾å…¥æ–‡æ¡£è¿›è¡Œæµ‹è¯•")
        print("  2. è¿è¡Œ 'python start.py' å¯åŠ¨æœåŠ¡")
        print("  3. è®¿é—® http://localhost:8000/docs æŸ¥çœ‹APIæ–‡æ¡£")
        print()

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
