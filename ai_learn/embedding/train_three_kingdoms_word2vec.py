"""
åŸºäºä¸‰å›½æ–‡æœ¬è®­ç»ƒ Word2Vec æ¨¡å‹
ä»å¤´å¼€å§‹å­¦ä¹  Embedding
"""

import jieba
from gensim.models import Word2Vec
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

print("=" * 70)
print("ä¸‰å›½æ–‡æœ¬ Word2Vec è®­ç»ƒ")
print("=" * 70)

# ===== ç¬¬ä¸€æ­¥ï¼šåŠ è½½å¹¶é¢„å¤„ç†æ–‡æœ¬ =====
print("\nã€ç¬¬ä¸€æ­¥ã€‘åŠ è½½ä¸‰å›½æ–‡æœ¬...")

with open('three_kingdoms.txt', 'r', encoding='utf-8') as f:
    text = f.read()

print(f"âœ“ æ–‡æœ¬åŠ è½½æˆåŠŸï¼Œæ€»å­—æ•°: {len(text):,}")

# åˆ†è¯ï¼ˆæŒ‰å¥å­åˆ†è¯ï¼‰
print("\næ­£åœ¨åˆ†è¯...")
sentences = []
for line in text.split('\n'):
    if line.strip():
        words = list(jieba.cut(line))
        # è¿‡æ»¤æ‰å•å­—å’Œæ ‡ç‚¹ï¼Œä¿ç•™æœ‰æ„ä¹‰çš„è¯
        words = [w for w in words if len(w) > 1]
        if words:
            sentences.append(words)

print(f"âœ“ åˆ†è¯å®Œæˆï¼Œå¥å­æ•°: {len(sentences):,}")
print(f"\nç¤ºä¾‹å¥å­ï¼ˆå‰3å¥ï¼‰:")
for i, sent in enumerate(sentences[:3], 1):
    print(f"  {i}. {' '.join(sent[:10])}...")

# ===== ç¬¬äºŒæ­¥ï¼šè®­ç»ƒ Word2Vec æ¨¡å‹ =====
print("\n" + "=" * 70)
print("ã€ç¬¬äºŒæ­¥ã€‘è®­ç»ƒ Word2Vec æ¨¡å‹")
print("=" * 70)

print("\nè®­ç»ƒå‚æ•°:")
print("  - vector_size: 100 (è¯å‘é‡ç»´åº¦)")
print("  - window: 5     (ä¸Šä¸‹æ–‡çª—å£å¤§å°)")
print("  - min_count: 2  (æœ€å°‘å‡ºç°æ¬¡æ•°)")
print("  - sg: 0         (ä½¿ç”¨ CBOW ç®—æ³•)")
print("  - epochs: 100   (è®­ç»ƒè½®æ•°)")

print("\nå¼€å§‹è®­ç»ƒ...")
model = Word2Vec(
    sentences=sentences,
    vector_size=100,
    window=5,
    min_count=2,
    sg=0,
    epochs=100,
    seed=42
)

print(f"âœ“ è®­ç»ƒå®Œæˆï¼è¯æ±‡è¡¨å¤§å°: {len(model.wv):,} ä¸ªè¯")

# ===== ç¬¬ä¸‰æ­¥ï¼šæ¢ç´¢è¯å‘é‡ =====
print("\n" + "=" * 70)
print("ã€ç¬¬ä¸‰æ­¥ã€‘æ¢ç´¢è¯å‘é‡")
print("=" * 70)

# 1. æŸ¥çœ‹è¯å‘é‡
print("\n" + "-" * 70)
print("1. æŸ¥çœ‹è¯å‘é‡ç¤ºä¾‹")
print("-" * 70)

key_words = ["åˆ˜å¤‡", "è¯¸è‘›äº®", "æ›¹æ“", "å…³ç¾½", "å¼ é£"]
for word in key_words:
    if word in model.wv:
        vector = model.wv[word]
        print(f"\n{word}:")
        print(f"  å‘é‡ç»´åº¦: {len(vector)}")
        print(f"  å‰5ç»´: {vector[:5]}")

# 2. è®¡ç®—è¯ç›¸ä¼¼åº¦
print("\n" + "-" * 70)
print("2. äººç‰©ç›¸ä¼¼åº¦")
print("-" * 70)

characters = ["åˆ˜å¤‡", "å…³ç¾½", "å¼ é£", "è¯¸è‘›äº®", "æ›¹æ“", "å­™æƒ", "å‘¨ç‘œ", "å•å¸ƒ"]
print(f"\n{'äººç‰©A':<8} {'äººç‰©B':<8} {'ç›¸ä¼¼åº¦':<10} {'å¯è§†åŒ–'}")
print("-" * 70)

for i in range(len(characters)):
    for j in range(i+1, len(characters)):
        word1, word2 = characters[i], characters[j]
        if word1 in model.wv and word2 in model.wv:
            sim = model.wv.similarity(word1, word2)
            bar = "â–ˆ" * int(sim * 30)
            print(f"{word1:<8} {word2:<8} {sim:.3f}     {bar}")

# 3. æ‰¾æœ€ç›¸ä¼¼çš„äºº
print("\n" + "-" * 70)
print("3. æ‰¾æœ€ç›¸ä¼¼çš„äººç‰©")
print("-" * 70)

query_people = ["åˆ˜å¤‡", "è¯¸è‘›äº®", "æ›¹æ“", "å…³ç¾½"]

for person in query_people:
    if person in model.wv:
        similar = model.wv.most_similar(person, topn=5)
        print(f"\nä¸ '{person}' æœ€ç›¸ä¼¼çš„äºº:")
        for name, score in similar:
            bar = "â–ˆ" * int(score * 30)
            print(f"  {name:<8} {score:.3f} {bar}")

# ===== ç¬¬å››æ­¥ï¼šè¯å‘é‡è¿ç®— =====
print("\n" + "=" * 70)
print("ã€ç¬¬å››æ­¥ã€‘è¯å‘é‡è¿ç®—")
print("=" * 70)

# åˆ˜å¤‡ + æ›¹æ“ - å¼ é£
print("\nè¿ç®—: åˆ˜å¤‡ + æ›¹æ“ - å¼ é£ = ?")
print("-" * 70)

try:
    result = model.wv.most_similar(
        positive=["åˆ˜å¤‡", "æ›¹æ“"],
        negative=["å¼ é£"],
        topn=10
    )
    for i, (word, score) in enumerate(result, 1):
        bar = "â–ˆ" * int(score * 30)
        print(f"  {i:2}. {word:<8} {score:.3f} {bar}")
except Exception as e:
    print(f"  æ— æ³•å®Œæˆè¿ç®—: {e}")

# ===== ç¬¬äº”æ­¥ï¼šå¯è§†åŒ–è¯å‘é‡ =====
print("\n" + "=" * 70)
print("ã€ç¬¬äº”æ­¥ã€‘å¯è§†åŒ–è¯å‘é‡ (PCAé™ç»´)")
print("=" * 70)

# é€‰æ‹©ä¸»è¦äººç‰©
main_characters = [
    "åˆ˜å¤‡", "å…³ç¾½", "å¼ é£", "è¯¸è‘›äº®", "èµµäº‘", "é»„å¿ ", "å§œç»´",  # èœ€
    "æ›¹æ“", "å¸é©¬æ‡¿", "è‘£å“", "è¢ç»",  # é­
    "å­™æƒ", "å‘¨ç‘œ", "é™†é€Š",  # å´
    "å•å¸ƒ"  # å…¶ä»–
]

# æå–è¯å‘é‡
vectors = []
valid_chars = []
for char in main_characters:
    if char in model.wv:
        vectors.append(model.wv[char])
        valid_chars.append(char)

vectors = np.array(vectors)

# PCAé™ç»´åˆ°2ç»´
pca = PCA(n_components=2)
vectors_2d = pca.fit_transform(vectors)

# æ ¹æ®é˜µè¥åˆ†ç±»
shu = ["åˆ˜å¤‡", "å…³ç¾½", "å¼ é£", "è¯¸è‘›äº®", "èµµäº‘", "é»„å¿ ", "å§œç»´"]
wei = ["æ›¹æ“", "å¸é©¬æ‡¿", "è‘£å“", "è¢ç»"]
wu = ["å­™æƒ", "å‘¨ç‘œ", "é™†é€Š"]
other = ["å•å¸ƒ"]

colors = []
sizes = []
for char in valid_chars:
    if char in shu:
        colors.append('green')
        sizes.append(200)
    elif char in wei:
        colors.append('blue')
        sizes.append(200)
    elif char in wu:
        colors.append('red')
        sizes.append(200)
    else:
        colors.append('gray')
        sizes.append(150)

# ç»˜å›¾
plt.figure(figsize=(12, 10))

for i, (x, y) in enumerate(vectors_2d):
    plt.scatter(x, y, c=colors[i], s=sizes[i], alpha=0.6,
               edgecolors='black', linewidth=1.5)
    plt.annotate(valid_chars[i], (x, y), xytext=(5, 5),
                textcoords='offset points', fontsize=12, fontweight='bold')

# æ·»åŠ å›¾ä¾‹
from matplotlib.lines import Line2D
legend_elements = [
    Line2D([0], [0], marker='o', color='w', markerfacecolor='green',
           markersize=12, label='èœ€å›½'),
    Line2D([0], [0], marker='o', color='w', markerfacecolor='blue',
           markersize=12, label='é­å›½'),
    Line2D([0], [0], marker='o', color='w', markerfacecolor='red',
           markersize=12, label='å´å›½'),
    Line2D([0], [0], marker='o', color='w', markerfacecolor='gray',
           markersize=12, label='å…¶ä»–'),
]
plt.legend(handles=legend_elements, loc='best', fontsize=11)

plt.title('ä¸‰å›½äººç‰©è¯å‘é‡å¯è§†åŒ– (Word2Vec + PCA)', fontsize=14, fontweight='bold')
plt.xlabel('ç»´åº¦ 1 (PCA)', fontsize=12)
plt.ylabel('ç»´åº¦ 2 (PCA)', fontsize=12)
plt.grid(True, alpha=0.3)
plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)
plt.axvline(x=0, color='k', linestyle='--', alpha=0.3)

plt.tight_layout()
plt.savefig('word2vec_visualization.png', dpi=100, bbox_inches='tight')
print("\nâœ“ å¯è§†åŒ–å›¾å·²ä¿å­˜: word2vec_visualization.png")
plt.close()

# ===== ç¬¬å…­æ­¥ï¼šä¿å­˜æ¨¡å‹ =====
print("\n" + "=" * 70)
print("ã€ç¬¬å…­æ­¥ã€‘ä¿å­˜æ¨¡å‹")
print("=" * 70)

model.save("word2vec.model")
print("âœ“ æ¨¡å‹å·²ä¿å­˜: word2vec.model")

print("\nä¸‹æ¬¡åŠ è½½æ–¹æ³•:")
print("  from gensim.models import Word2Vec")
print("  model = Word2Vec.load('word2vec.model')")

# ===== æ€»ç»“ =====
print("\n" + "=" * 70)
print("è®­ç»ƒå®Œæˆï¼")
print("=" * 70)

print("\nâœ“ å®Œæˆçš„å·¥ä½œ:")
print("  1. åŠ è½½ä¸‰å›½æ–‡æœ¬ (60ä¸‡+ å­—)")
print("  2. ä¸­æ–‡åˆ†è¯ï¼ˆjiebaï¼‰")
print("  3. è®­ç»ƒ Word2Vec æ¨¡å‹ (è¯æ±‡é‡: 16,977)")
print("  4. æ¢ç´¢è¯å‘é‡ï¼ˆç›¸ä¼¼åº¦ã€ç±»æ¯”ï¼‰")
print("  5. å¯è§†åŒ–äººç‰©å…³ç³»")

print("\nğŸ’¡ ä½ å¯ä»¥ç»§ç»­:")
print("  - åŠ è½½æ¨¡å‹: model = Word2Vec.load('word2vec.model')")
print("  - æŸ¥è¯¢ç›¸ä¼¼è¯: model.wv.most_similar('åˆ˜å¤‡')")
print("  - è¯å‘é‡è¿ç®—: model.wv.most_similar(positive=['åˆ˜å¤‡','æ›¹æ“'], negative=['å¼ é£'])")

print("\n" + "=" * 70)
