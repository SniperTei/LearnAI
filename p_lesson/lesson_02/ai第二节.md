### Prompt 编写技巧
* 任务
* 上下文
* 示例
* 角色
* 格式
* 语气

* 限制模型的输出格式
	* 使用JSON格式
	* 提供示例
	* 面相不同角色做解释
		* 把我当做小朋友解释XXX
 
 
 ### 部署使用modelScope


#### modelscope， vllm， autoDL 三者结合是一套低成本、高性能、易落地的 AI 模型部署与应用闭环，完美适配你的 iOS+FastAPI 技术栈

* AutoDL 提供高性价比的 GPU 算力，解决本地无高端显卡的问题；
* ModelScope 提供丰富的中文开源模型（如通义千问、多模态生成模型），一键调用无需从零训练；
* vLLM 负责大幅提升模型推理性能，解决高并发下的吞吐量低、延迟高的痛点。

三者结合后，你可以用极低的成本搭建一个生产级的 AI 推理 API，再通过 FastAPI 转发给 iOS 客户端，实现端到端的 AI 应用。

* Ollama 瓶体AutoDL，本地部署

http://case.wucai.com/ball
