### RAG技术树


### RAFT方法
#### Retreval Augmented Fine Tuning
* 本质上，RAFT 是在训练一个"信息筛选器"，而不是简单的"问答系统"。这使得模型在面对不完美的检索结果时，依然能给出高质量答案
* 主要提升扛干扰能力。
* RAFT 主要适合：
  - ✅ 检索质量很差且难以优化的场景
  - ✅ 需要精确引用的领域（医学、法律）
  - ✅ 有专门团队维护的垂直领域应用
#### FT有两种模式

#### 一般FT的成本是多少？
* 90万数据量用于FT，训练可能会有4-6个epoch，1epoch 8张H800 32小时；
=> 完整的4-6epoch 需要7天
  * epoch是训练次数
* 90万的数据量，是有值的筛选后的数据；来自于真正的业务场景，全量数据可能会有900万；
筛选完整的客户沟通的交流数据(尽可能多的轮次对话交流)

### nativeRAG 
#### 目前采用监督微调的还不多，

### CASE DeepSeek+Faiss搭建本地知识库检索
* 

### RAG高效召回方法
* 相似语义改写
* 双向改写
  * 将查询改写成文档(Query2Doc)或为文档生成查询(Doc2Query)
* 索引拓展
* small-to-big
  * 擅长长文档，多文档

### GraphRAG
* 构建社区层级
* 为这些社区层级生成摘要，类似small-to-big
* 提供了两种查询
  * local query -- 细节
  * global query -- 宏观

#### graphRAG是红管，上帝视角
如果不考虑成本 =>  GraphRAG 质量不错
nativeRAG => 现有阶段大家采用的方式
把三国演义全文都生成chunk，召回100个，重排取top20，能达到这个效果么
chunk1： 曹操和刘备在谈论xxx
chunk2： 曹操和曹丕在xxx

曹操和刘备是盟友和敌人的关系，对这个只是的理解是站在整体的角度进行的summary
#### graphRAG的缺点
* 成本高
* 构建成本高
* 维护成本高

### Qwen-Agent
1. 知道聊天模型将用户查询中的指令与信息进行分开
2. 分块阅读：
3. 逐步推理：在基于文档的问题回答中，一个典型的


### FAQ
#### 如果要用Rerank的话是不是要找匹配的embedding模型才行？

#### Rerank是专门来评分的吗？
* 是的，Rerank是专门用来评分的

#### 召回的目的是什么？
* 召回的目的是为了找到与用户查询相关的文档，以便用户能够快速获取到所需的信息。

#### 用大模型直接回答不是完了吗？ 为何还要加graphRAG
* LLM + RAG 直接回答： 先通过召回10个，rerankTop5 => 回答你的问题；
* chunk的颗粒度进行回答；
* LLM对三国演义会有全面的理解么

